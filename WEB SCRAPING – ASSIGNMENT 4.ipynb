{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "8bf66ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "1eea1a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets connect to the driver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\HP\\Desktop\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e43c94ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(' https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3aebb8",
   "metadata": {},
   "source": [
    "# Q1. Scrape the details of most viewed videos on YouTube from Wikipedia.\n",
    "Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ca304250",
   "metadata": {},
   "outputs": [],
   "source": [
    "Name=[]\n",
    "\n",
    "name_tags=driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[2]\")\n",
    "for i in name_tags[0:30]:\n",
    "    name=i.text\n",
    "    Name.append(name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "44c7fd56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"Baby Shark Dance\"[3]',\n",
       " '\"Despacito\"[6]',\n",
       " '\"Johny Johny Yes Papa\"[12]',\n",
       " '\"Shape of You\"[13]',\n",
       " '\"Bath Song\"[15]',\n",
       " '\"See You Again\"[16]',\n",
       " '\"Phonics Song with Two Words\"[21]',\n",
       " '\"Uptown Funk\"[22]',\n",
       " '\"Learning Colors – Colorful Eggs on a Farm\"[23]',\n",
       " '\"Gangnam Style\"[24]',\n",
       " '\"Masha and the Bear – Recipe for Disaster\"[29]',\n",
       " '\"Wheels on the Bus\"[30]',\n",
       " '\"Dame Tu Cosita\"[31]',\n",
       " '\"Sugar\"[32]',\n",
       " '\"Roar\"[33]',\n",
       " '\"Counting Stars\"[34]',\n",
       " '\"Sorry\"[35]',\n",
       " '\"Axel F\"[36]',\n",
       " '\"Thinking Out Loud\"[37]',\n",
       " '\"Baa Baa Black Sheep\"[38]',\n",
       " '\"Dark Horse\"[39]',\n",
       " '\"Faded\"[40]',\n",
       " '\"Girls Like You\"[41]',\n",
       " '\"Let Her Go\"[42]',\n",
       " '\"Bailando\"[43]',\n",
       " '\"Perfect\"[44]',\n",
       " '\"Lean On\"[45]',\n",
       " '\"Waka Waka (This Time for Africa)\"[46]',\n",
       " '\"Shake It Off\"[47]',\n",
       " '\"Humpty the train on a fruits ride\"[48]']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9daf8a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rank=[]\n",
    "\n",
    "rank_tags=driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[1]\")\n",
    "for i in rank_tags[0:30]:\n",
    "    rank=i.text\n",
    "    Rank.append(rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3b03d7cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1.',\n",
       " '2.',\n",
       " '3.',\n",
       " '4.',\n",
       " '5.',\n",
       " '6.',\n",
       " '7.',\n",
       " '8.',\n",
       " '9.',\n",
       " '10.',\n",
       " '11.',\n",
       " '12.',\n",
       " '13.',\n",
       " '14.',\n",
       " '15.',\n",
       " '16.',\n",
       " '17.',\n",
       " '18.',\n",
       " '18.',\n",
       " '20.',\n",
       " '21.',\n",
       " '22.',\n",
       " '23.',\n",
       " '24.',\n",
       " '25.',\n",
       " '26.',\n",
       " '27.',\n",
       " '28.',\n",
       " '29.',\n",
       " '30.']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7119eaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Views=[]\n",
    "\n",
    "views_tags=driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[4]\")\n",
    "for i in views_tags[0:30]:\n",
    "    views=i.text\n",
    "    Views.append(views)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "773b1159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['11.58',\n",
       " '7.99',\n",
       " '6.50',\n",
       " '5.83',\n",
       " '5.68',\n",
       " '5.68',\n",
       " '4.96',\n",
       " '4.73',\n",
       " '4.69',\n",
       " '4.58',\n",
       " '4.51',\n",
       " '4.50',\n",
       " '4.11',\n",
       " '3.77',\n",
       " '3.67',\n",
       " '3.67',\n",
       " '3.60',\n",
       " '3.56',\n",
       " '3.51',\n",
       " '3.41',\n",
       " '3.37',\n",
       " '3.36',\n",
       " '3.34',\n",
       " '3.32',\n",
       " '3.29',\n",
       " '3.28',\n",
       " '3.28',\n",
       " '3.27',\n",
       " '3.22',\n",
       " '3.19']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e619743d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Upload_date=[]\n",
    "\n",
    "upload_tags=driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[5]\")\n",
    "for i in upload_tags[0:30]:\n",
    "    upload=i.text\n",
    "    Upload_date.append(upload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a1c7502d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['June 17, 2016',\n",
       " 'January 12, 2017',\n",
       " 'October 8, 2016',\n",
       " 'January 30, 2017',\n",
       " 'May 2, 2018',\n",
       " 'April 6, 2015',\n",
       " 'March 6, 2014',\n",
       " 'November 19, 2014',\n",
       " 'February 27, 2018',\n",
       " 'July 15, 2012',\n",
       " 'January 31, 2012',\n",
       " 'May 24, 2018',\n",
       " 'April 5, 2018',\n",
       " 'January 14, 2015',\n",
       " 'September 5, 2013',\n",
       " 'May 31, 2013',\n",
       " 'October 22, 2015',\n",
       " 'June 16, 2009',\n",
       " 'October 7, 2014',\n",
       " 'June 25, 2018',\n",
       " 'February 20, 2014',\n",
       " 'December 3, 2015',\n",
       " 'May 31, 2018',\n",
       " 'July 25, 2012',\n",
       " 'April 11, 2014',\n",
       " 'November 9, 2017',\n",
       " 'March 22, 2015',\n",
       " 'June 4, 2010',\n",
       " 'August 18, 2014',\n",
       " 'January 26, 2018']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Upload_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e02fd036",
   "metadata": {},
   "outputs": [],
   "source": [
    "Artist=[]\n",
    "\n",
    "artist_tags=driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[3]\")\n",
    "for i in artist_tags[0:30]:\n",
    "    artist=i.text\n",
    "    Artist.append(artist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1cc56331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Pinkfong Baby Shark - Kids' Songs & Stories\",\n",
       " 'Luis Fonsi',\n",
       " 'LooLoo Kids',\n",
       " 'Ed Sheeran',\n",
       " 'Cocomelon – Nursery Rhymes',\n",
       " 'Wiz Khalifa',\n",
       " 'ChuChu TV',\n",
       " 'Mark Ronson',\n",
       " 'Miroshka TV',\n",
       " 'Psy',\n",
       " 'Get Movies',\n",
       " 'Cocomelon – Nursery Rhymes',\n",
       " 'El Chombo',\n",
       " 'Maroon 5',\n",
       " 'Katy Perry',\n",
       " 'OneRepublic',\n",
       " 'Justin Bieber',\n",
       " 'Crazy Frog',\n",
       " 'Ed Sheeran',\n",
       " 'Cocomelon – Nursery Rhymes',\n",
       " 'Katy Perry',\n",
       " 'Alan Walker',\n",
       " 'Maroon 5',\n",
       " 'Passenger',\n",
       " 'Enrique Iglesias',\n",
       " 'Ed Sheeran',\n",
       " 'Major Lazer',\n",
       " 'Shakira',\n",
       " 'Taylor Swift',\n",
       " 'Kiddiestv Hindi – Nursery Rhymes & Kids Songs']"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "445693ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 30 30 30\n"
     ]
    }
   ],
   "source": [
    "print(len(Name),len(Views),len(Artist),len(Upload_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "75157ac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Upload date</th>\n",
       "      <th>Views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>\"Baby Shark Dance\"[3]</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>11.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>\"Despacito\"[6]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>7.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>\"Johny Johny Yes Papa\"[12]</td>\n",
       "      <td>LooLoo Kids</td>\n",
       "      <td>October 8, 2016</td>\n",
       "      <td>6.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>\"Shape of You\"[13]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>January 30, 2017</td>\n",
       "      <td>5.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>\"Bath Song\"[15]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 2, 2018</td>\n",
       "      <td>5.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>\"See You Again\"[16]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>5.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>\"Phonics Song with Two Words\"[21]</td>\n",
       "      <td>ChuChu TV</td>\n",
       "      <td>March 6, 2014</td>\n",
       "      <td>4.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>\"Uptown Funk\"[22]</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>November 19, 2014</td>\n",
       "      <td>4.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"[23]</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>February 27, 2018</td>\n",
       "      <td>4.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>\"Gangnam Style\"[24]</td>\n",
       "      <td>Psy</td>\n",
       "      <td>July 15, 2012</td>\n",
       "      <td>4.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"[29]</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>January 31, 2012</td>\n",
       "      <td>4.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>\"Wheels on the Bus\"[30]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 24, 2018</td>\n",
       "      <td>4.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>\"Dame Tu Cosita\"[31]</td>\n",
       "      <td>El Chombo</td>\n",
       "      <td>April 5, 2018</td>\n",
       "      <td>4.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>\"Sugar\"[32]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>January 14, 2015</td>\n",
       "      <td>3.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>\"Roar\"[33]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>September 5, 2013</td>\n",
       "      <td>3.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>\"Counting Stars\"[34]</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>May 31, 2013</td>\n",
       "      <td>3.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>\"Sorry\"[35]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>3.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>\"Axel F\"[36]</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>June 16, 2009</td>\n",
       "      <td>3.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18.</td>\n",
       "      <td>\"Thinking Out Loud\"[37]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>October 7, 2014</td>\n",
       "      <td>3.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>\"Baa Baa Black Sheep\"[38]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>June 25, 2018</td>\n",
       "      <td>3.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>\"Dark Horse\"[39]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>February 20, 2014</td>\n",
       "      <td>3.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>\"Faded\"[40]</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>December 3, 2015</td>\n",
       "      <td>3.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>\"Girls Like You\"[41]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>May 31, 2018</td>\n",
       "      <td>3.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>\"Let Her Go\"[42]</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>July 25, 2012</td>\n",
       "      <td>3.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>\"Bailando\"[43]</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>April 11, 2014</td>\n",
       "      <td>3.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>\"Perfect\"[44]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>November 9, 2017</td>\n",
       "      <td>3.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>\"Lean On\"[45]</td>\n",
       "      <td>Major Lazer</td>\n",
       "      <td>March 22, 2015</td>\n",
       "      <td>3.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[46]</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>June 4, 2010</td>\n",
       "      <td>3.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>\"Shake It Off\"[47]</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>August 18, 2014</td>\n",
       "      <td>3.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>\"Humpty the train on a fruits ride\"[48]</td>\n",
       "      <td>Kiddiestv Hindi – Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>January 26, 2018</td>\n",
       "      <td>3.19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                             Name  \\\n",
       "0    1.                            \"Baby Shark Dance\"[3]   \n",
       "1    2.                                   \"Despacito\"[6]   \n",
       "2    3.                       \"Johny Johny Yes Papa\"[12]   \n",
       "3    4.                               \"Shape of You\"[13]   \n",
       "4    5.                                  \"Bath Song\"[15]   \n",
       "5    6.                              \"See You Again\"[16]   \n",
       "6    7.                \"Phonics Song with Two Words\"[21]   \n",
       "7    8.                                \"Uptown Funk\"[22]   \n",
       "8    9.  \"Learning Colors – Colorful Eggs on a Farm\"[23]   \n",
       "9   10.                              \"Gangnam Style\"[24]   \n",
       "10  11.   \"Masha and the Bear – Recipe for Disaster\"[29]   \n",
       "11  12.                          \"Wheels on the Bus\"[30]   \n",
       "12  13.                             \"Dame Tu Cosita\"[31]   \n",
       "13  14.                                      \"Sugar\"[32]   \n",
       "14  15.                                       \"Roar\"[33]   \n",
       "15  16.                             \"Counting Stars\"[34]   \n",
       "16  17.                                      \"Sorry\"[35]   \n",
       "17  18.                                     \"Axel F\"[36]   \n",
       "18  18.                          \"Thinking Out Loud\"[37]   \n",
       "19  20.                        \"Baa Baa Black Sheep\"[38]   \n",
       "20  21.                                 \"Dark Horse\"[39]   \n",
       "21  22.                                      \"Faded\"[40]   \n",
       "22  23.                             \"Girls Like You\"[41]   \n",
       "23  24.                                 \"Let Her Go\"[42]   \n",
       "24  25.                                   \"Bailando\"[43]   \n",
       "25  26.                                    \"Perfect\"[44]   \n",
       "26  27.                                    \"Lean On\"[45]   \n",
       "27  28.           \"Waka Waka (This Time for Africa)\"[46]   \n",
       "28  29.                               \"Shake It Off\"[47]   \n",
       "29  30.          \"Humpty the train on a fruits ride\"[48]   \n",
       "\n",
       "                                           Artist        Upload date  Views  \n",
       "0     Pinkfong Baby Shark - Kids' Songs & Stories      June 17, 2016  11.58  \n",
       "1                                      Luis Fonsi   January 12, 2017   7.99  \n",
       "2                                     LooLoo Kids    October 8, 2016   6.50  \n",
       "3                                      Ed Sheeran   January 30, 2017   5.83  \n",
       "4                      Cocomelon – Nursery Rhymes        May 2, 2018   5.68  \n",
       "5                                     Wiz Khalifa      April 6, 2015   5.68  \n",
       "6                                       ChuChu TV      March 6, 2014   4.96  \n",
       "7                                     Mark Ronson  November 19, 2014   4.73  \n",
       "8                                     Miroshka TV  February 27, 2018   4.69  \n",
       "9                                             Psy      July 15, 2012   4.58  \n",
       "10                                     Get Movies   January 31, 2012   4.51  \n",
       "11                     Cocomelon – Nursery Rhymes       May 24, 2018   4.50  \n",
       "12                                      El Chombo      April 5, 2018   4.11  \n",
       "13                                       Maroon 5   January 14, 2015   3.77  \n",
       "14                                     Katy Perry  September 5, 2013   3.67  \n",
       "15                                    OneRepublic       May 31, 2013   3.67  \n",
       "16                                  Justin Bieber   October 22, 2015   3.60  \n",
       "17                                     Crazy Frog      June 16, 2009   3.56  \n",
       "18                                     Ed Sheeran    October 7, 2014   3.51  \n",
       "19                     Cocomelon – Nursery Rhymes      June 25, 2018   3.41  \n",
       "20                                     Katy Perry  February 20, 2014   3.37  \n",
       "21                                    Alan Walker   December 3, 2015   3.36  \n",
       "22                                       Maroon 5       May 31, 2018   3.34  \n",
       "23                                      Passenger      July 25, 2012   3.32  \n",
       "24                               Enrique Iglesias     April 11, 2014   3.29  \n",
       "25                                     Ed Sheeran   November 9, 2017   3.28  \n",
       "26                                    Major Lazer     March 22, 2015   3.28  \n",
       "27                                        Shakira       June 4, 2010   3.27  \n",
       "28                                   Taylor Swift    August 18, 2014   3.22  \n",
       "29  Kiddiestv Hindi – Nursery Rhymes & Kids Songs   January 26, 2018   3.19  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making dataframe\n",
    "\n",
    "df=pd.DataFrame({'Rank':Rank,'Name':Name,'Artist':Artist,'Upload date':Upload_date,'Views':Views})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc2a2dd",
   "metadata": {},
   "source": [
    "# Q2. Scrape the details team India’s international fixtures from bcci.tv.\n",
    "Url = https://www.bcci.tv/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b41a6ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.bcci.tv/international/fixtures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "b69473e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Match_title = []\n",
    "\n",
    "Match_tags=driver.find_elements(By.XPATH,'/html/body/div[2]/div[2]/div/div/div/div[2]/div[3]/div/div[1]/div/div[4]/div/span[1]')\n",
    "for i in Match_tags:\n",
    "    match=i.text\n",
    "    Match_title.append(match)\n",
    "    \n",
    "    \n",
    "Match_tags=driver.find_elements(By.XPATH,'/html/body/div[2]/div[2]/div/div/div/div[2]/div[3]/div/div[4]/div/div[4]/div/span[1]')\n",
    "for i in Match_tags:\n",
    "    match=i.text\n",
    "    Match_title.append(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "16a8827f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1st ODI -', '1st ODI -']"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Match_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "9bd91a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "Series=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "6b454b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "Series_tags=driver.find_elements(By.XPATH,'/html/body/div[2]/div[2]/div/div/div/div[2]/div[3]/div/div[5]/div/div[1]/h5[2]/span')\n",
    "for i in Series_tags:\n",
    "    series=i.text\n",
    "    Series.append(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "b36f0083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['INDIA TOUR OF BANGLADESH ODI SERIES 2022-23']"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "aa245766",
   "metadata": {},
   "outputs": [],
   "source": [
    "Series_tags=driver.find_elements(By.XPATH,'/html/body/div[2]/div[2]/div/div/div/div[2]/div[3]/div/div[1]/div/div[1]/h5[2]/span')\n",
    "for i in Series_tags:\n",
    "    series=i.text\n",
    "    Series.append(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "5feb5736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['INDIA TOUR OF BANGLADESH ODI SERIES 2022-23',\n",
       " 'INDIA TOUR OF NEW ZEALAND ODI SERIES 2022-23']"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "b6de99b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Place = []\n",
    "\n",
    "Place_tags=driver.find_elements(By.XPATH,'/html/body/div[2]/div[2]/div/div/div/div[2]/div[3]/div/div[1]/div/div[4]/div/span[2]')\n",
    "for i in Place_tags:\n",
    "    place=i.text\n",
    "    Place.append(place)\n",
    "    \n",
    "    \n",
    "Place_tags=driver.find_elements(By.XPATH,'/html/body/div[2]/div[2]/div/div/div/div[2]/div[3]/div/div[4]/div/div[4]/div/span[2]')\n",
    "for i in Place_tags:\n",
    "    place=i.text\n",
    "    Place.append(place)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "1c1f91cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Eden Park,', 'Shere Bangla National Stadium, Mirpur,']"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "7c521a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "Time = []\n",
    "time_tags=driver.find_elements(By.XPATH,'/html/body/div[2]/div[2]/div/div/div/div[2]/div[3]/div/div[1]/div/div[1]/div/div[2]/h5')\n",
    "for i in time_tags:\n",
    "    time=i.text\n",
    "    Time.append(time)\n",
    "    \n",
    "    \n",
    "time_tags=driver.find_elements(By.XPATH,'/html/body/div[2]/div[2]/div/div/div/div[2]/div[3]/div/div[4]/div/div[1]/div/div[2]/h5')\n",
    "for i in Date_tags:\n",
    "    time=i.text\n",
    "    Time.append(time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "8f362c71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['7:00 AM IST', '4 DEC 2022']"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "2cb8760a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Date = []\n",
    "Date_tags=driver.find_elements(By.XPATH,'/html/body/div[2]/div[2]/div/div/div/div[2]/div[3]/div/div[1]/div/div[1]/div/div[1]/h5')\n",
    "for i in Date_tags:\n",
    "    date=i.text\n",
    "    Date.append(date)\n",
    "    \n",
    "    \n",
    "Date_tags=driver.find_elements(By.XPATH,'/html/body/div[2]/div[2]/div/div/div/div[2]/div[3]/div/div[4]/div/div[1]/div/div[1]/h5')\n",
    "for i in Date_tags:\n",
    "    date=i.text\n",
    "    Date.append(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "d3ff5387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['25 NOV 2022', '4 DEC 2022']"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "161abcc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 2 2 2 2\n"
     ]
    }
   ],
   "source": [
    "print(len(Match_title),len(Series),len(Place),len(Date),len(Time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0b6e59",
   "metadata": {},
   "source": [
    "# 3. Scrape the details of selenium exception from guru99.com.\n",
    "Url = https://www.guru99.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "5ab587b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.guru99.com/exception-handling-selenium.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "348a672c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Name = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "fce340cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "Name_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[1]/strong')\n",
    "for i in Name_tags:\n",
    "    name=i.text\n",
    "    Name.append(name)\n",
    "    \n",
    "\n",
    "Name_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[2]/strong')\n",
    "for i in Name_tags:\n",
    "    name=i.text\n",
    "    Name.append(name)\n",
    "    \n",
    "\n",
    "Name_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[3]/strong')\n",
    "for i in Name_tags:\n",
    "    name=i.text\n",
    "    Name.append(name)\n",
    "    \n",
    "    \n",
    "\n",
    "Name_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[4]/strong')\n",
    "for i in Name_tags:\n",
    "    name=i.text\n",
    "    Name.append(name)\n",
    "    \n",
    "    \n",
    "\n",
    "Name_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[5]/strong')\n",
    "for i in Name_tags:\n",
    "    name=i.text\n",
    "    Name.append(name)\n",
    "    \n",
    "\n",
    "Name_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[6]/strong')\n",
    "for i in Name_tags:\n",
    "    name=i.text\n",
    "    Name.append(name)\n",
    "    \n",
    "\n",
    "Name_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[7]/strong')\n",
    "for i in Name_tags:\n",
    "    name=i.text\n",
    "    Name.append(name)\n",
    "    \n",
    "    \n",
    "Name_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[8]/strong')\n",
    "for i in Name_tags:\n",
    "    name=i.text\n",
    "    Name.append(name)\n",
    "    \n",
    "\n",
    "Name_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[9]/strong')\n",
    "for i in Name_tags:\n",
    "    name=i.text\n",
    "    Name.append(name)\n",
    "    \n",
    "\n",
    "Name_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[10]/strong')\n",
    "for i in Name_tags:\n",
    "    name=i.text\n",
    "    Name.append(name)\n",
    "    \n",
    "    \n",
    "\n",
    "Name_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[11]/strong')\n",
    "for i in Name_tags:\n",
    "    name=i.text\n",
    "    Name.append(name)\n",
    "    \n",
    "    \n",
    "\n",
    "Name_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[12]/strong')\n",
    "for i in Name_tags:\n",
    "    name=i.text\n",
    "    Name.append(name)\n",
    "    \n",
    "\n",
    "Name_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[13]/strong')\n",
    "for i in Name_tags:\n",
    "    name=i.text\n",
    "    Name.append(name)\n",
    "    \n",
    "\n",
    "Name_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[14]/strong')\n",
    "for i in Name_tags:\n",
    "    name=i.text\n",
    "    Name.append(name)\n",
    "    \n",
    "Name_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[15]/strong')\n",
    "for i in Name_tags:\n",
    "    name=i.text\n",
    "    Name.append(name)\n",
    "    \n",
    "\n",
    "Name_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[16]/strong')\n",
    "for i in Name_tags:\n",
    "    name=i.text\n",
    "    Name.append(name)\n",
    "    \n",
    "\n",
    "Name_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[17]/strong')\n",
    "for i in Name_tags:\n",
    "    name=i.text\n",
    "    Name.append(name)\n",
    "    \n",
    "    \n",
    "\n",
    "Name_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[18]/strong')\n",
    "for i in Name_tags:\n",
    "    name=i.text\n",
    "    Name.append(name)\n",
    "    \n",
    "    \n",
    "\n",
    "Name_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[19]/strong')\n",
    "for i in Name_tags:\n",
    "    name=i.text\n",
    "    Name.append(name)\n",
    "    \n",
    "\n",
    "Name_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[20]/strong')\n",
    "for i in Name_tags:\n",
    "    name=i.text\n",
    "    Name.append(name)\n",
    "    \n",
    "\n",
    "Name_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[21]/strong')\n",
    "for i in Name_tags:\n",
    "    name=i.text\n",
    "    Name.append(name)\n",
    "    \n",
    "    \n",
    "Name_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[22]/strong')\n",
    "for i in Name_tags:\n",
    "    name=i.text\n",
    "    Name.append(name)\n",
    "    \n",
    "\n",
    "Name_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[23]/strong')\n",
    "for i in Name_tags:\n",
    "    name=i.text\n",
    "    Name.append(name)\n",
    "    \n",
    "\n",
    "Name_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[24]/strong')\n",
    "for i in Name_tags:\n",
    "    name=i.text\n",
    "    Name.append(name)\n",
    "    \n",
    "    \n",
    "\n",
    "Name_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[25]/strong')\n",
    "for i in Name_tags:\n",
    "    name=i.text\n",
    "    Name.append(name)\n",
    "    \n",
    "    \n",
    "\n",
    "Name_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[26]/strong')\n",
    "for i in Name_tags:\n",
    "    name=i.text\n",
    "    Name.append(name)\n",
    "    \n",
    "\n",
    "Name_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[27]/strong')\n",
    "for i in Name_tags:\n",
    "    name=i.text\n",
    "    Name.append(name)\n",
    "    \n",
    "\n",
    "Name_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[28]/strong')\n",
    "for i in Name_tags:\n",
    "    name=i.text\n",
    "    Name.append(name)\n",
    "    \n",
    "Name_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[29]/strong')\n",
    "for i in Name_tags:\n",
    "    name=i.text\n",
    "    Name.append(name)\n",
    "    \n",
    "Name_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[30]/strong')\n",
    "for i in Name_tags:\n",
    "    name=i.text\n",
    "    Name.append(name)\n",
    "    \n",
    "\n",
    "Name_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[31]/strong')\n",
    "for i in Name_tags:\n",
    "    name=i.text\n",
    "    Name.append(name)\n",
    "    \n",
    "\n",
    "Name_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[32]/strong')\n",
    "for i in Name_tags:\n",
    "    name=i.text\n",
    "    Name.append(name)\n",
    "    \n",
    "    \n",
    "\n",
    "Name_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[33]/strong')\n",
    "for i in Name_tags:\n",
    "    name=i.text\n",
    "    Name.append(name)\n",
    "    \n",
    "    \n",
    "\n",
    "Name_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[34]/strong')\n",
    "for i in Name_tags:\n",
    "    name=i.text\n",
    "    Name.append(name)\n",
    "    \n",
    "\n",
    "Name_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[35]/strong')\n",
    "for i in Name_tags:\n",
    "    name=i.text\n",
    "    Name.append(name)\n",
    "    \n",
    "\n",
    "Name_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[36]/strong')\n",
    "for i in Name_tags:\n",
    "    name=i.text\n",
    "    Name.append(name)\n",
    "    \n",
    "    \n",
    "Name_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[37]/strong')\n",
    "for i in Name_tags:\n",
    "    name=i.text\n",
    "    Name.append(name)\n",
    "    \n",
    "\n",
    "Name_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[38]/strong')\n",
    "for i in Name_tags:\n",
    "    name=i.text\n",
    "    Name.append(name)\n",
    "    \n",
    "\n",
    "Name_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[39]/strong')\n",
    "for i in Name_tags:\n",
    "    name=i.text\n",
    "    Name.append(name)\n",
    "    \n",
    "    \n",
    "\n",
    "Name_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[40]/strong')\n",
    "for i in Name_tags:\n",
    "    name=i.text\n",
    "    Name.append(name)\n",
    "    \n",
    "    \n",
    "\n",
    "Name_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[41]/strong')\n",
    "for i in Name_tags:\n",
    "    name=i.text\n",
    "    Name.append(name)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "545ab5fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1. ElementNotVisibleException:',\n",
       " '2. ElementNotSelectableException:',\n",
       " '3. NoSuchElementException:',\n",
       " '4. NoSuchFrameException:',\n",
       " '5. NoAlertPresentException:',\n",
       " '6. NoSuchWindowException:',\n",
       " '7. StaleElementReferenceException:',\n",
       " '8. SessionNotFoundException:',\n",
       " '9. TimeoutException:',\n",
       " '10. WebDriverException:',\n",
       " '11. ConnectionClosedException:',\n",
       " '12. ElementClickInterceptedException:',\n",
       " '13. ElementNotInteractableException:',\n",
       " '14. ErrorInResponseException:',\n",
       " '15. ErrorHandler.UnknownServerException:',\n",
       " '16. ImeActivationFailedException:',\n",
       " '17. ImeNotAvailableException:',\n",
       " '18. InsecureCertificateException:',\n",
       " '19. InvalidArgumentException:',\n",
       " '20. InvalidCookieDomainException:',\n",
       " '21. InvalidCoordinatesException:',\n",
       " '22. InvalidElementStateException:',\n",
       " '23. InvalidSessionIdException:',\n",
       " '24. InvalidSwitchToTargetException:',\n",
       " '25. JavascriptException:',\n",
       " '26. JsonException:',\n",
       " '27. NoSuchAttributeException:',\n",
       " '28. MoveTargetOutOfBoundsException:',\n",
       " '29. NoSuchContextException:',\n",
       " '30. NoSuchCookieException:',\n",
       " '31. NotFoundException:',\n",
       " '32. RemoteDriverServerException:',\n",
       " '33. ScreenshotException:',\n",
       " '34. SessionNotCreatedException:',\n",
       " '35. UnableToSetCookieException:',\n",
       " '36. UnexpectedTagNameException:',\n",
       " '37. UnhandledAlertException:',\n",
       " '38. UnexpectedAlertPresentException:',\n",
       " '39. UnknownMethodException:',\n",
       " '40. UnreachableBrowserException:',\n",
       " '41. UnsupportedCommandException:']"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "17104826",
   "metadata": {},
   "outputs": [],
   "source": [
    "Description = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "c75e0abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Description_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[1]')\n",
    "for i in Description_tags:\n",
    "    description=i.text\n",
    "    Description.append(description)\n",
    "    \n",
    "Description_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[2]')\n",
    "for i in Description_tags:\n",
    "    description=i.text\n",
    "    Description.append(description)\n",
    "    \n",
    "Description_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[3]')\n",
    "for i in Description_tags:\n",
    "    description=i.text\n",
    "    Description.append(description)\n",
    "    \n",
    "Description_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[4]')\n",
    "for i in Description_tags:\n",
    "    description=i.text\n",
    "    Description.append(description)\n",
    "    \n",
    "Description_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[5]')\n",
    "for i in Description_tags:\n",
    "    description=i.text\n",
    "    Description.append(description)\n",
    "    \n",
    "Description_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[6]')\n",
    "for i in Description_tags:\n",
    "    description=i.text\n",
    "    Description.append(description)\n",
    "    \n",
    "Description_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[7]')\n",
    "for i in Description_tags:\n",
    "    description=i.text\n",
    "    Description.append(description)\n",
    "    \n",
    "Description_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[8]')\n",
    "for i in Description_tags:\n",
    "    description=i.text\n",
    "    Description.append(description)\n",
    "    \n",
    "Description_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[9]')\n",
    "for i in Description_tags:\n",
    "    description=i.text\n",
    "    Description.append(description)\n",
    "    \n",
    "Description_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[10]')\n",
    "for i in Description_tags:\n",
    "    description=i.text\n",
    "    Description.append(description)\n",
    "    \n",
    "Description_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[11]')\n",
    "for i in Description_tags:\n",
    "    description=i.text\n",
    "    Description.append(description)\n",
    "    \n",
    "Description_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[12]')\n",
    "for i in Description_tags:\n",
    "    description=i.text\n",
    "    Description.append(description)\n",
    "    \n",
    "Description_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[13]')\n",
    "for i in Description_tags:\n",
    "    description=i.text\n",
    "    Description.append(description)\n",
    "    \n",
    "Description_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[14]')\n",
    "for i in Description_tags:\n",
    "    description=i.text\n",
    "    Description.append(description)\n",
    "    \n",
    "Description_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[15]')\n",
    "for i in Description_tags:\n",
    "    description=i.text\n",
    "    Description.append(description)\n",
    "    \n",
    "Description_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[16]')\n",
    "for i in Description_tags:\n",
    "    description=i.text\n",
    "    Description.append(description)\n",
    "    \n",
    "Description_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[17]')\n",
    "for i in Description_tags:\n",
    "    description=i.text\n",
    "    Description.append(description)\n",
    "    \n",
    "Description_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[18]')\n",
    "for i in Description_tags:\n",
    "    description=i.text\n",
    "    Description.append(description)\n",
    "    \n",
    "Description_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[19]')\n",
    "for i in Description_tags:\n",
    "    description=i.text\n",
    "    Description.append(description)\n",
    "    \n",
    "Description_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[20]')\n",
    "for i in Description_tags:\n",
    "    description=i.text\n",
    "    Description.append(description)\n",
    "    \n",
    "Description_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[21]')\n",
    "for i in Description_tags:\n",
    "    description=i.text\n",
    "    Description.append(description)\n",
    "    \n",
    "Description_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[22]')\n",
    "for i in Description_tags:\n",
    "    description=i.text\n",
    "    Description.append(description)\n",
    "    \n",
    "Description_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[23]')\n",
    "for i in Description_tags:\n",
    "    description=i.text\n",
    "    Description.append(description)\n",
    "    \n",
    "Description_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[24]')\n",
    "for i in Description_tags:\n",
    "    description=i.text\n",
    "    Description.append(description)\n",
    "    \n",
    "Description_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[25]')\n",
    "for i in Description_tags:\n",
    "    description=i.text\n",
    "    Description.append(description)\n",
    "    \n",
    "Description_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[26]')\n",
    "for i in Description_tags:\n",
    "    description=i.text\n",
    "    Description.append(description)\n",
    "    \n",
    "Description_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[27]')\n",
    "for i in Description_tags:\n",
    "    description=i.text\n",
    "    Description.append(description)\n",
    "    \n",
    "Description_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[28]')\n",
    "for i in Description_tags:\n",
    "    description=i.text\n",
    "    Description.append(description)\n",
    "    \n",
    "Description_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[29]')\n",
    "for i in Description_tags:\n",
    "    description=i.text\n",
    "    Description.append(description)\n",
    "    \n",
    "Description_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[30]')\n",
    "for i in Description_tags:\n",
    "    description=i.text\n",
    "    Description.append(description)\n",
    "    \n",
    "Description_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[31]')\n",
    "for i in Description_tags:\n",
    "    description=i.text\n",
    "    Description.append(description)\n",
    "    \n",
    "Description_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[32]')\n",
    "for i in Description_tags:\n",
    "    description=i.text\n",
    "    Description.append(description)\n",
    "    \n",
    "Description_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[33]')\n",
    "for i in Description_tags:\n",
    "    description=i.text\n",
    "    Description.append(description)\n",
    "    \n",
    "Description_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[34]')\n",
    "for i in Description_tags:\n",
    "    description=i.text\n",
    "    Description.append(description)\n",
    "    \n",
    "Description_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[35]')\n",
    "for i in Description_tags:\n",
    "    description=i.text\n",
    "    Description.append(description)\n",
    "    \n",
    "Description_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[36]')\n",
    "for i in Description_tags:\n",
    "    description=i.text\n",
    "    Description.append(description)\n",
    "    \n",
    "Description_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[37]')\n",
    "for i in Description_tags:\n",
    "    description=i.text\n",
    "    Description.append(description)\n",
    "    \n",
    "Description_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[38]')\n",
    "for i in Description_tags:\n",
    "    description=i.text\n",
    "    Description.append(description)\n",
    "    \n",
    "Description_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[39]')\n",
    "for i in Description_tags:\n",
    "    description=i.text\n",
    "    Description.append(description)\n",
    "    \n",
    "Description_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[40]')\n",
    "for i in Description_tags:\n",
    "    description=i.text\n",
    "    Description.append(description)\n",
    "    \n",
    "Description_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[41]')\n",
    "for i in Description_tags:\n",
    "    description=i.text\n",
    "    Description.append(description)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "1686c663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1. ElementNotVisibleException: This type of Selenium exception occurs when an existing element in DOM has a feature set as hidden.',\n",
       " '2. ElementNotSelectableException: This Selenium exception occurs when an element is presented in the DOM, but you can be able to select. Therefore, it is not possible to interact.',\n",
       " '3. NoSuchElementException: This Exception occurs if an element could not be found.',\n",
       " '4. NoSuchFrameException: This Exception occurs if the frame target to be switched to does not exist.',\n",
       " '5. NoAlertPresentException: This Exception occurs when you switch to no presented alert.',\n",
       " '6. NoSuchWindowException: This Exception occurs if the window target to be switch does not exist.',\n",
       " '7. StaleElementReferenceException: This Selenium exception occurs happens when the web element is detached from the current DOM.',\n",
       " '8. SessionNotFoundException: The WebDriver is acting after you quit the browser.',\n",
       " '9. TimeoutException: Thrown when there is not enough time for a command to be completed. For Example, the element searched wasn’t found in the specified time.',\n",
       " '10. WebDriverException: This Exception takes place when the WebDriver is acting right after you close the browser.',\n",
       " '11. ConnectionClosedException: This type of Exception takes place when there is a disconnection in the driver.',\n",
       " '12. ElementClickInterceptedException: The command may not be completed as the element receiving the events is concealing the element which was requested clicked.',\n",
       " '13. ElementNotInteractableException: This Selenium exception is thrown when any element is presented in the DOM. However, it is impossible to interact with such an element.',\n",
       " '14. ErrorInResponseException: This happens while interacting with the Firefox extension or the remote driver server.',\n",
       " '15. ErrorHandler.UnknownServerException: Exception is used as a placeholder in case if the server returns an error without a stack trace.',\n",
       " '16. ImeActivationFailedException: This expectation will occur when IME engine activation has failed.',\n",
       " '17. ImeNotAvailableException: It takes place when IME support is unavailable.',\n",
       " '18. InsecureCertificateException: Navigation made the user agent to hit a certificate warning. This can cause by an invalid or expired TLS certificate.',\n",
       " '19. InvalidArgumentException: It occurs when an argument does not belong to the expected type.',\n",
       " '20. InvalidCookieDomainException: This happens when you try to add a cookie under a different domain instead of current URL.',\n",
       " '21. InvalidCoordinatesException: This type of Exception matches an interacting operation that is not valid.',\n",
       " '22. InvalidElementStateException: It occurs when command can’t be finished when the element is invalid.',\n",
       " '23. InvalidSessionIdException: This Exception took place when the given session ID is not included in the list of active sessions. It means the session does not exist or is inactive either.',\n",
       " '24. InvalidSwitchToTargetException: This occurs when the frame or window target to be switched does not exist.',\n",
       " '25. JavascriptException: This issue occurs while executing JavaScript given by the user.',\n",
       " '26. JsonException: It occurs when you afford to get the session when the session is not created.',\n",
       " '27. NoSuchAttributeException: This kind of Exception occurs when the attribute of an element could not be found.',\n",
       " '28. MoveTargetOutOfBoundsException: It takes place if the target provided to the ActionChains move() methodology is not valid. For Example, out of the document.',\n",
       " '29. NoSuchContextException: ContextAware does mobile device testing.',\n",
       " '30. NoSuchCookieException: This Exception occurs when no cookie matching with the given pathname found for all the associated cookies of the currently browsing document.',\n",
       " '31. NotFoundException: This Exception is a subclass of WebDriverException. This will occur when an element on the DOM does not exist.',\n",
       " '32. RemoteDriverServerException: This Selenium exception is thrown when the server is not responding because of the problem that the capabilities described are not proper.',\n",
       " '33. ScreenshotException: It is not possible to capture a screen.',\n",
       " '34. SessionNotCreatedException: It happens when a new session could not be successfully created.',\n",
       " '35. UnableToSetCookieException: This occurs if a driver is unable to set a cookie.',\n",
       " '36. UnexpectedTagNameException: Happens if a support class did not get a web element as expected.',\n",
       " '37. UnhandledAlertException: This expectation occurs when there is an alert, but WebDriver is not able to perform Alert operation.',\n",
       " '38. UnexpectedAlertPresentException: It occurs when there is the appearance of an unexpected alert.',\n",
       " '39. UnknownMethodException: This Exception happens when the requested command matches with a known URL but and not matching with a methodology for a specific URL.',\n",
       " '40. UnreachableBrowserException: This Exception occurs only when the browser is not able to be opened or crashed because of some reason.',\n",
       " '41. UnsupportedCommandException: This occurs when remote WebDriver doesn’t send valid commands as expected.']"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "5dec43b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41 41\n"
     ]
    }
   ],
   "source": [
    "print(len(Name),len(Description))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3464875b",
   "metadata": {},
   "source": [
    "# Q4. Scrape the details of State-wise GDP of India from statisticstime.com.\n",
    "Url = http://statisticstimes.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "92c4c1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\HP\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "12690983",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.statisticstimes.com/economy/india-statistics.php')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8021645a",
   "metadata": {},
   "source": [
    "# 5. Scrape the details of trending repositories on Github.com.\n",
    "Url = https://github.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "16c0e5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://github.com/trending')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "f81b09de",
   "metadata": {},
   "outputs": [],
   "source": [
    "Repository_title = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "42fa31e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Repository_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[3]/div/div[2]/article[1]/h1/a')\n",
    "for i in Repository_tags:\n",
    "    repository=i.text\n",
    "    Repository_title.append(repository)\n",
    "    \n",
    "    \n",
    "Repository_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[3]/div/div[2]/article[2]/h1/a')\n",
    "for i in Repository_tags:\n",
    "    repository=i.text\n",
    "    Repository_title.append(repository)\n",
    "    \n",
    "Repository_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[3]/div/div[2]/article[3]/h1/a')\n",
    "for i in Repository_tags:\n",
    "    repository=i.text\n",
    "    Repository_title.append(repository)\n",
    "    \n",
    "Repository_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[3]/div/div[2]/article[4]/h1/a')\n",
    "for i in Repository_tags:\n",
    "    repository=i.text\n",
    "    Repository_title.append(repository)\n",
    "    \n",
    "Repository_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[3]/div/div[2]/article[5]/h1/a')\n",
    "for i in Repository_tags:\n",
    "    repository=i.text\n",
    "    Repository_title.append(repository)\n",
    "    \n",
    "    \n",
    "Repository_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[3]/div/div[2]/article[6]/h1/a')\n",
    "for i in Repository_tags:\n",
    "    repository=i.text\n",
    "    Repository_title.append(repository)\n",
    "    \n",
    "Repository_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[3]/div/div[2]/article[7]/h1/a')\n",
    "for i in Repository_tags:\n",
    "    repository=i.text\n",
    "    Repository_title.append(repository)\n",
    "    \n",
    "Repository_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[3]/div/div[2]/article[8]/h1/a')\n",
    "for i in Repository_tags:\n",
    "    repository=i.text\n",
    "    Repository_title.append(repository)\n",
    "    \n",
    "Repository_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[3]/div/div[2]/article[9]/h1/a')\n",
    "for i in Repository_tags:\n",
    "    repository=i.text\n",
    "    Repository_title.append(repository)\n",
    "    \n",
    "Repository_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[3]/div/div[2]/article[10]/h1/a')\n",
    "for i in Repository_tags:\n",
    "    repository=i.text\n",
    "    Repository_title.append(repository)\n",
    "    \n",
    "Repository_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[3]/div/div[2]/article[11]/h1/a')\n",
    "for i in Repository_tags:\n",
    "    repository=i.text\n",
    "    Repository_title.append(repository)\n",
    "    \n",
    "Repository_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[3]/div/div[2]/article[12]/h1/a')\n",
    "for i in Repository_tags:\n",
    "    repository=i.text\n",
    "    Repository_title.append(repository)\n",
    "    \n",
    "Repository_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[3]/div/div[2]/article[13]/h1/a')\n",
    "for i in Repository_tags:\n",
    "    repository=i.text\n",
    "    Repository_title.append(repository)\n",
    "    \n",
    "Repository_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[3]/div/div[2]/article[14]/h1/a')\n",
    "for i in Repository_tags:\n",
    "    repository=i.text\n",
    "    Repository_title.append(repository)\n",
    "    \n",
    "Repository_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[3]/div/div[2]/article[15]/h1/a')\n",
    "for i in Repository_tags:\n",
    "    repository=i.text\n",
    "    Repository_title.append(repository)\n",
    "    \n",
    "Repository_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[3]/div/div[2]/article[16]/h1/a')\n",
    "for i in Repository_tags:\n",
    "    repository=i.text\n",
    "    Repository_title.append(repository)\n",
    "    \n",
    "Repository_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[3]/div/div[2]/article[17]/h1/a')\n",
    "for i in Repository_tags:\n",
    "    repository=i.text\n",
    "    Repository_title.append(repository)\n",
    "    \n",
    "Repository_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[3]/div/div[2]/article[18]/h1/a')\n",
    "for i in Repository_tags:\n",
    "    repository=i.text\n",
    "    Repository_title.append(repository)\n",
    "    \n",
    "Repository_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[3]/div/div[2]/article[19]/h1/a')\n",
    "for i in Repository_tags:\n",
    "    repository=i.text\n",
    "    Repository_title.append(repository)\n",
    "    \n",
    "Repository_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[3]/div/div[2]/article[20]/h1/a')\n",
    "for i in Repository_tags:\n",
    "    repository=i.text\n",
    "    Repository_title.append(repository)\n",
    "    \n",
    "Repository_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[3]/div/div[2]/article[21]/h1/a')\n",
    "for i in Repository_tags:\n",
    "    repository=i.text\n",
    "    Repository_title.append(repository)\n",
    "    \n",
    "Repository_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[3]/div/div[2]/article[22]/h1/a')\n",
    "for i in Repository_tags:\n",
    "    repository=i.text\n",
    "    Repository_title.append(repository)\n",
    "    \n",
    "Repository_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[3]/div/div[2]/article[23]/h1/a')\n",
    "for i in Repository_tags:\n",
    "    repository=i.text\n",
    "    Repository_title.append(repository)\n",
    "    \n",
    "Repository_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[3]/div/div[2]/article[24]/h1/a')\n",
    "for i in Repository_tags:\n",
    "    repository=i.text\n",
    "    Repository_title.append(repository)\n",
    "    \n",
    "Repository_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[3]/div/div[2]/article[25]/h1/a')\n",
    "for i in Repository_tags:\n",
    "    repository=i.text\n",
    "    Repository_title.append(repository)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "177a25da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hellof2e / quark-design',\n",
       " 'remix-run / remix',\n",
       " 'NCSC-NL / OpenSSL-2022',\n",
       " 'AMAI-GmbH / AI-Expert-Roadmap',\n",
       " 'TeamNewPipe / NewPipe',\n",
       " 'yangshun / tech-interview-handbook',\n",
       " 'Eilonh / s3crets_scanner',\n",
       " 'openssl / openssl',\n",
       " 'mastodon / mastodon',\n",
       " 'jwasham / coding-interview-university',\n",
       " 'poteto / hiring-without-whiteboards',\n",
       " 'mattermost / focalboard',\n",
       " 'bharathsudharsan / TinyML-CAM',\n",
       " 'AvaloniaUI / Avalonia',\n",
       " 'kubernetes / client-go',\n",
       " 'vuetifyjs / vuetify',\n",
       " 'bluesky-social / atproto',\n",
       " 'SnapKit / SnapKit',\n",
       " 'lightningnetwork / lnd',\n",
       " 'geohot / tinygrad',\n",
       " 'ocornut / imgui',\n",
       " 'NVIDIA / DeepLearningExamples',\n",
       " 'ripienaar / free-for-dev',\n",
       " 'bellard / quickjs',\n",
       " 'nushell / nushell']"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Repository_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "e543deb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Repository_description = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "f455cc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "Repository_description_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[3]/div/div[2]/article[1]/p')\n",
    "for i in Repository_description_tags:\n",
    "    Repository=i.text\n",
    "    Repository_description.append(Repository)\n",
    "    \n",
    "Repository_description_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[3]/div/div[2]/article[2]/p')\n",
    "for i in Repository_description_tags:\n",
    "    Repository=i.text\n",
    "    Repository_description.append(Repository)\n",
    "    \n",
    "Repository_description_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[3]/div/div[2]/article[3]/p')\n",
    "for i in Repository_description_tags:\n",
    "    Repository=i.text\n",
    "    Repository_description.append(Repository)\n",
    "    \n",
    "Repository_description_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[3]/div/div[2]/article[4]/p')\n",
    "for i in Repository_description_tags:\n",
    "    Repository=i.text\n",
    "    Repository_description.append(Repository)\n",
    "    \n",
    "Repository_description_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[3]/div/div[2]/article[5]/p')\n",
    "for i in Repository_description_tags:\n",
    "    Repository=i.text\n",
    "    Repository_description.append(Repository)\n",
    "    \n",
    "Repository_description_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[3]/div/div[2]/article[6]/p')\n",
    "for i in Repository_description_tags:\n",
    "    Repository=i.text\n",
    "    Repository_description.append(Repository)\n",
    "    \n",
    "Repository_description_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[3]/div/div[2]/article[7]/p')\n",
    "for i in Repository_description_tags:\n",
    "    Repository=i.text\n",
    "    Repository_description.append(Repository)\n",
    "    \n",
    "Repository_description_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[3]/div/div[2]/article[8]/p')\n",
    "for i in Repository_description_tags:\n",
    "    Repository=i.text\n",
    "    Repository_description.append(Repository)\n",
    "    \n",
    "Repository_description_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[3]/div/div[2]/article[9]/p')\n",
    "for i in Repository_description_tags:\n",
    "    Repository=i.text\n",
    "    Repository_description.append(Repository)\n",
    "    \n",
    "Repository_description_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[3]/div/div[2]/article[10]/p')\n",
    "for i in Repository_description_tags:\n",
    "    Repository=i.text\n",
    "    Repository_description.append(Repository)\n",
    "    \n",
    "for i in Repository_description_tags:\n",
    "    Repository=i.text\n",
    "    Repository_description.append(Repository)\n",
    "    \n",
    "Repository_description_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[3]/div/div[2]/article[11]/p')\n",
    "for i in Repository_description_tags:\n",
    "    Repository=i.text\n",
    "    Repository_description.append(Repository)\n",
    "    \n",
    "Repository_description_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[3]/div/div[2]/article[12]/p')\n",
    "for i in Repository_description_tags:\n",
    "    Repository=i.text\n",
    "    Repository_description.append(Repository)\n",
    "    \n",
    "Repository_description_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[3]/div/div[2]/article[13]/p')\n",
    "for i in Repository_description_tags:\n",
    "    Repository=i.text\n",
    "    Repository_description.append(Repository)\n",
    "    \n",
    "Repository_description_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[3]/div/div[2]/article[14]/p')\n",
    "for i in Repository_description_tags:\n",
    "    Repository=i.text\n",
    "    Repository_description.append(Repository)\n",
    "    \n",
    "Repository_description_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[3]/div/div[2]/article[15]/p')\n",
    "for i in Repository_description_tags:\n",
    "    Repository=i.text\n",
    "    Repository_description.append(Repository)\n",
    "    \n",
    "Repository_description_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[3]/div/div[2]/article[16]/p')\n",
    "for i in Repository_description_tags:\n",
    "    Repository=i.text\n",
    "    Repository_description.append(Repository)\n",
    "    \n",
    "Repository_description_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[3]/div/div[2]/article[17]/p')\n",
    "for i in Repository_description_tags:\n",
    "    Repository=i.text\n",
    "    Repository_description.append(Repository)\n",
    "    \n",
    "Repository_description_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[3]/div/div[2]/article[18]/p')\n",
    "for i in Repository_description_tags:\n",
    "    Repository=i.text\n",
    "    Repository_description.append(Repository)\n",
    "    \n",
    "Repository_description_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[3]/div/div[2]/article[19]/p')\n",
    "for i in Repository_description_tags:\n",
    "    Repository=i.text\n",
    "    Repository_description.append(Repository)\n",
    "    \n",
    "Repository_description_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[3]/div/div[2]/article[20]/p')\n",
    "for i in Repository_description_tags:\n",
    "    Repository=i.text\n",
    "    Repository_description.append(Repository)\n",
    "    \n",
    "Repository_description_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[3]/div/div[2]/article[21]/p')\n",
    "for i in Repository_description_tags:\n",
    "    Repository=i.text\n",
    "    Repository_description.append(Repository)\n",
    "    \n",
    "Repository_description_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[3]/div/div[2]/article[22]/p')\n",
    "for i in Repository_description_tags:\n",
    "    Repository=i.text\n",
    "    Repository_description.append(Repository)\n",
    "    \n",
    "Repository_description_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[3]/div/div[2]/article[23]/p')\n",
    "for i in Repository_description_tags:\n",
    "    Repository=i.text\n",
    "    Repository_description.append(Repository)\n",
    "    \n",
    "Repository_description_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[3]/div/div[2]/article[24]/p')\n",
    "for i in Repository_description_tags:\n",
    "    Repository=i.text\n",
    "    Repository_description.append(Repository)\n",
    "\n",
    "Repository_description_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[3]/div/div[2]/article[25]/p')\n",
    "for i in Repository_description_tags:\n",
    "    Repository=i.text\n",
    "    Repository_description.append(Repository)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "ad0d8bc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Next generation Frontend component library, it can be used in any framework or no framework at the same time.(下一代前端组件库，它可以同时在任意框架或无框架中使用。)',\n",
       " 'Build Better Websites. Create modern, resilient user experiences with web fundamentals.',\n",
       " 'Operational information regarding CVE-2022-3602 and CVE-2022-3786, two vulnerabilities in OpenSSL 3',\n",
       " 'Roadmap to becoming an Artificial Intelligence Expert in 2022',\n",
       " 'A libre lightweight streaming front-end for Android.',\n",
       " '💯 Curated coding interview preparation materials for busy software engineers',\n",
       " 'TLS/SSL and crypto library',\n",
       " 'Your self-hosted, globally interconnected microblogging community',\n",
       " 'A complete computer science study plan to become a software engineer.',\n",
       " 'A complete computer science study plan to become a software engineer.',\n",
       " \"⭐️ Companies that don't have a broken hiring process\",\n",
       " 'Focalboard is an open source, self-hosted alternative to Trello, Notion, and Asana.',\n",
       " \"Code for MobiCom'22 paper 'TinyML-CAM: 80 FPS Image Recognition in 1 Kb RAM'\",\n",
       " 'A cross-platform UI framework for .NET',\n",
       " 'Go client for Kubernetes.',\n",
       " '🐉 Material Component Framework for Vue',\n",
       " 'A social networking technology created by Bluesky',\n",
       " 'A Swift Autolayout DSL for iOS & OS X',\n",
       " 'Lightning Network Daemon ⚡️',\n",
       " 'You like pytorch? You like micrograd? You love tinygrad! ❤️',\n",
       " 'Dear ImGui: Bloat-free Graphical User interface for C++ with minimal dependencies',\n",
       " 'Deep Learning Examples',\n",
       " 'A list of SaaS, PaaS and IaaS offerings that have free tiers of interest to devops and infradev',\n",
       " 'Public repository of the QuickJS Javascript Engine. Pull requests are not accepted. Use the mailing list to submit patches.',\n",
       " 'A new type of shell']"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Repository_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "f84e80f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Contributors_count=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "781ada95",
   "metadata": {},
   "outputs": [],
   "source": [
    "Contributors_count_tags=driver.find_elements(By.XPATH,'//h2[@class=\"h4 mb-3\"]')\n",
    "for i in Contributors_count_tags:\n",
    "    contributors=i.text\n",
    "    Contributors_count.append(contributors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "c354d3eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Contributors_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca0dbdc",
   "metadata": {},
   "source": [
    "# Q6. Scrape the details of top 100 songs on billiboard.com.\n",
    "Url = https:/www.billboard.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "813e5e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.billboard.com/charts/hot-100/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "975c42bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Song_name = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "503e7662",
   "metadata": {},
   "outputs": [],
   "source": [
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[2]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "\n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[3]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[4]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[5]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[6]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[7]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "\n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[8]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[9]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[10]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[11]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[12]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "\n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[13]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[14]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[15]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[16]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[17]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "\n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[18]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[19]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[20]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[21]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[22]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "\n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[23]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[24]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[25]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[26]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[27]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "\n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[28]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[29]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[30]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[31]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[32]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "\n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[33]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[34]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[35]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[36]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[37]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "\n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[38]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[39]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[40]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[41]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[42]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[43]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[44]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[45]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[46]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[47]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[48]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[49]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[50]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[51]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "\n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[52]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[53]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[54]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[55]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[56]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "\n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[57]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[58]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[59]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[60]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[61]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "\n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[62]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[63]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[64]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[65]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[66]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "\n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[67]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[68]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[69]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[70]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[71]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "\n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[72]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[73]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[74]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[75]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[76]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "\n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[77]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[78]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[79]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[80]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[81]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "\n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[82]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[83]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[84]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[85]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[86]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "\n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[87]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[88]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[89]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[90]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[91]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[92]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[93]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[94]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[95]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[96]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[97]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[98]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[89]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[99]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[100]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[101]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[102]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[103]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[104]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[105]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[106]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[107]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[108]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[109]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)\n",
    "    \n",
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[110]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song_name.append(song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "33b12e43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Anti-Hero',\n",
       " 'Lavender Haze',\n",
       " 'Maroon',\n",
       " 'Snow On The Beach',\n",
       " 'Midnight Rain',\n",
       " 'Bejeweled',\n",
       " 'Question...?',\n",
       " \"You're On Your Own, Kid\",\n",
       " 'Karma',\n",
       " 'Vigilante Shit',\n",
       " 'Unholy',\n",
       " 'Bad Habit',\n",
       " 'Mastermind',\n",
       " 'Labyrinth',\n",
       " 'Sweet Nothing',\n",
       " 'As It Was',\n",
       " 'I Like You (A Happier Song)',\n",
       " \"I Ain't Worried\",\n",
       " 'You Proof',\n",
       " \"Would've, Could've, Should've\",\n",
       " 'Bigger Than The Whole Sky',\n",
       " 'Super Freaky Girl',\n",
       " 'Sunroof',\n",
       " \"I'm Good (Blue)\",\n",
       " 'Under The Influence',\n",
       " 'The Great War',\n",
       " 'Vegas',\n",
       " 'Something In The Orange',\n",
       " 'Wasted On You',\n",
       " 'Jimmy Cooks',\n",
       " 'Wait For U',\n",
       " 'Paris',\n",
       " 'High Infidelity',\n",
       " 'Tomorrow 2',\n",
       " 'Titi Me Pregunto',\n",
       " 'About Damn Time',\n",
       " 'The Kind Of Love We Make',\n",
       " 'Late Night Talking',\n",
       " 'Cuff It',\n",
       " 'She Had Me At Heads Carolina',\n",
       " 'Glitch',\n",
       " 'Me Porto Bonito',\n",
       " 'Die For You',\n",
       " 'California Breeze',\n",
       " 'Dear Reader',\n",
       " 'Forever',\n",
       " 'Hold Me Closer',\n",
       " 'Just Wanna Rock',\n",
       " '5 Foot 9',\n",
       " 'Unstoppable',\n",
       " 'Thank God',\n",
       " 'Fall In Love',\n",
       " 'Rock And A Hard Place',\n",
       " 'Golden Hour',\n",
       " 'Heyy',\n",
       " 'Half Of Me',\n",
       " 'Until I Found You',\n",
       " 'Victoria’s Secret',\n",
       " 'Son Of A Sinner',\n",
       " \"Star Walkin' (League Of Legends Worlds Anthem)\",\n",
       " 'Romantic Homicide',\n",
       " 'What My World Spins Around',\n",
       " 'Real Spill',\n",
       " \"Don't Come Lookin'\",\n",
       " 'Monotonia',\n",
       " 'Stand On It',\n",
       " 'Never Hating',\n",
       " 'Wishful Drinking',\n",
       " 'No Se Va',\n",
       " 'Free Mind',\n",
       " 'Not Finished',\n",
       " 'Music For A Sushi Restaurant',\n",
       " 'Pop Out',\n",
       " 'Staying Alive',\n",
       " 'Poland',\n",
       " 'Whiskey On You',\n",
       " 'Billie Eilish.',\n",
       " 'Betty (Get Money)',\n",
       " '2 Be Loved (Am I Ready)',\n",
       " 'Wait In The Truck',\n",
       " 'All Mine',\n",
       " 'La Bachata',\n",
       " 'Last Last',\n",
       " 'Glimpse Of Us',\n",
       " 'Freestyle',\n",
       " 'Calm Down',\n",
       " 'Gatubela',\n",
       " 'Evergreen',\n",
       " 'Pick Me Up',\n",
       " 'Gotta Move On',\n",
       " 'Perfect Timing',\n",
       " 'Country On',\n",
       " 'Snap',\n",
       " 'She Likes It',\n",
       " 'Made You Look',\n",
       " 'Dark Red',\n",
       " 'From Now On',\n",
       " 'Forget Me',\n",
       " 'Miss You',\n",
       " 'Despecha']"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Song_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "ca249d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(Song_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "38a2d0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Artist_name=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "4f3f7d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[2]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "\n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[3]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[4]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[5]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[6]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[7]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "\n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[8]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[9]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[10]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[11]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[13]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "\n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[14]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[15]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[16]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[17]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[18]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "\n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[19]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[20]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[21]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[22]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[23]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "\n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[24]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[25]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[26]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[27]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[28]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[29]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[30]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "\n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[31]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[32]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[33]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[34]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[35]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[36]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[37]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[38]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[39]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[40]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[41]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[42]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[43]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[44]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[45]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[46]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[47]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[48]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[49]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[50]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[51]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[52]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[53]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[54]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[55]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[56]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[57]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[58]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[59]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[60]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[61]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[62]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[63]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[64]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[65]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[66]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[67]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[68]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[69]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[70]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[71]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[72]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[73]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[74]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[75]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[76]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[77]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[78]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[79]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[80]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[81]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[82]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[83]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[84]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[85]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[86]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[87]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[88]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[89]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[90]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[91]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[92]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[93]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[94]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[95]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[96]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[97]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[98]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[99]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[100]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[101]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[102]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[103]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[104]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[105]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[106]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[107]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[108]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[109]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[110]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)\n",
    "    \n",
    "Artist_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[111]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Artist_tags[0:100]:\n",
    "    Artist=i.text\n",
    "    Artist_name.append(Artist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "11d2d312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Taylor Swift',\n",
       " 'Taylor Swift',\n",
       " 'Taylor Swift',\n",
       " 'Taylor Swift Featuring Lana Del Rey',\n",
       " 'Taylor Swift',\n",
       " 'Taylor Swift',\n",
       " 'Taylor Swift',\n",
       " 'Taylor Swift',\n",
       " 'Taylor Swift',\n",
       " 'Taylor Swift',\n",
       " 'Sam Smith & Kim Petras',\n",
       " 'Steve Lacy',\n",
       " 'Taylor Swift',\n",
       " 'Taylor Swift',\n",
       " 'Taylor Swift',\n",
       " 'Harry Styles',\n",
       " 'Post Malone Featuring Doja Cat',\n",
       " 'OneRepublic',\n",
       " 'Morgan Wallen',\n",
       " 'Taylor Swift',\n",
       " 'Taylor Swift',\n",
       " 'Nicki Minaj',\n",
       " 'Nicky Youre & dazy',\n",
       " 'David Guetta & Bebe Rexha',\n",
       " 'Chris Brown',\n",
       " 'Taylor Swift',\n",
       " 'Doja Cat',\n",
       " 'Zach Bryan',\n",
       " 'Morgan Wallen',\n",
       " 'Drake Featuring 21 Savage',\n",
       " 'Future Featuring Drake & Tems',\n",
       " 'Taylor Swift',\n",
       " 'Taylor Swift',\n",
       " 'GloRilla & Cardi B',\n",
       " 'Bad Bunny',\n",
       " 'Lizzo',\n",
       " 'Luke Combs',\n",
       " 'Harry Styles',\n",
       " 'Beyonce',\n",
       " 'Cole Swindell',\n",
       " 'Taylor Swift',\n",
       " 'Bad Bunny & Chencho Corleone',\n",
       " 'The Weeknd',\n",
       " 'Lil Baby',\n",
       " 'Taylor Swift',\n",
       " 'Lil Baby Featuring Fridayy',\n",
       " 'Elton John & Britney Spears',\n",
       " 'Lil Uzi Vert',\n",
       " 'Tyler Hubbard',\n",
       " 'Sia',\n",
       " 'Kane Brown With Katelyn Brown',\n",
       " 'Bailey Zimmerman',\n",
       " 'Bailey Zimmerman',\n",
       " 'JVKE',\n",
       " 'Lil Baby',\n",
       " 'Thomas Rhett Featuring Riley Green',\n",
       " 'Stephen Sanchez',\n",
       " 'Jax',\n",
       " 'Jelly Roll',\n",
       " 'Lil Nas X',\n",
       " 'd4vd',\n",
       " 'Jordan Davis',\n",
       " 'Lil Baby',\n",
       " 'Jackson Dean',\n",
       " 'Shakira + Ozuna',\n",
       " 'Lil Baby',\n",
       " 'Lil Baby & Young Thug',\n",
       " 'Ingrid Andress With Sam Hunt',\n",
       " 'Grupo Frontera',\n",
       " 'Tems',\n",
       " 'Lil Baby',\n",
       " 'Harry Styles',\n",
       " 'Lil Baby & Nardo Wick',\n",
       " 'DJ Khaled Featuring Drake & Lil Baby',\n",
       " 'Lil Yachty',\n",
       " 'Nate Smith',\n",
       " 'Armani White',\n",
       " 'Yung Gravy',\n",
       " 'Lizzo',\n",
       " 'HARDY Featuring Lainey Wilson',\n",
       " 'Brent Faiyaz',\n",
       " 'Manuel Turizo',\n",
       " 'Burna Boy',\n",
       " 'Joji',\n",
       " 'Lil Baby',\n",
       " 'Rema & Selena Gomez',\n",
       " 'Karol G x Maldy',\n",
       " 'Omar Apollo',\n",
       " 'Gabby Barrett',\n",
       " 'Diddy & Bryson Tiller',\n",
       " 'Lil Baby',\n",
       " 'Luke Bryan',\n",
       " 'Rosa Linn',\n",
       " 'Russell Dickerson & Jake Scott',\n",
       " 'Meghan Trainor',\n",
       " 'Steve Lacy',\n",
       " 'Lil Baby Featuring Future',\n",
       " 'Lewis Capaldi',\n",
       " 'Oliver Tree & Robin Schulz',\n",
       " 'Rosalia']"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Artist_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "e0711885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(Artist_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "id": "7d35de3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Last_Week_Rank = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "b10ac0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[2]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[3]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[4]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[5]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[6]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[7]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[8]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[9]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[10]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[11]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[12]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "\n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[13]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[14]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[15]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[16]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[17]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[18]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[19]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[20]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[21]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "\n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[22]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[23]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[24]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[25]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[26]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "\n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[27]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[28]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[29]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "\n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[30]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[31]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[32]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[33]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[34]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "\n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[35]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[36]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[37]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[38]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[39]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[40]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[41]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "\n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[42]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[43]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[44]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[45]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[46]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "\n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[47]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[48]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[49]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[50]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[51]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[52]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[53]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[54]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[55]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[56]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[57]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[58]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[59]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[60]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[61]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[62]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[63]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[64]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[65]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[66]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[66]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[67]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[68]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[69]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[70]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[71]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[72]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[73]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[74]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[75]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[76]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[77]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[78]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[79]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[80]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[81]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[82]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[83]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[84]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[85]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[86]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[87]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[88]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[89]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[90]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[91]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[92]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[93]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[94]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[95]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[96]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[97]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[98]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[99]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[100]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[101]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[102]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[103]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[104]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[105]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[106]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[107]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[108]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n",
    "Last_week_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[109]/ul/li[4]/ul/li[4]/span')\n",
    "for i in Last_week_rank_tags[0:100]:\n",
    "    last_week_rank=i.text\n",
    "    Last_Week_Rank.append(last_week_rank)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "7ecae4ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '1',\n",
       " '2',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '3',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '-',\n",
       " '-',\n",
       " '9',\n",
       " '11',\n",
       " '14',\n",
       " '29',\n",
       " '-',\n",
       " '13',\n",
       " '12',\n",
       " '17',\n",
       " '31',\n",
       " '18',\n",
       " '-',\n",
       " '-',\n",
       " '24',\n",
       " '25',\n",
       " '20',\n",
       " '23',\n",
       " '27',\n",
       " '33',\n",
       " '28',\n",
       " '-',\n",
       " '30',\n",
       " '37',\n",
       " '4',\n",
       " '-',\n",
       " '8',\n",
       " '34',\n",
       " '86',\n",
       " '41',\n",
       " '39',\n",
       " '38',\n",
       " '36',\n",
       " '35',\n",
       " '62',\n",
       " '21',\n",
       " '63',\n",
       " '48',\n",
       " '47',\n",
       " '49',\n",
       " '43',\n",
       " '43',\n",
       " '46',\n",
       " '51',\n",
       " '10',\n",
       " '50',\n",
       " '-',\n",
       " '22',\n",
       " '19',\n",
       " '60',\n",
       " '67',\n",
       " '65',\n",
       " '26',\n",
       " '74',\n",
       " '15',\n",
       " '66',\n",
       " '40',\n",
       " '55',\n",
       " '71',\n",
       " '59',\n",
       " '72',\n",
       " '75',\n",
       " '78',\n",
       " '82',\n",
       " '73',\n",
       " '56',\n",
       " '84',\n",
       " '89',\n",
       " '83',\n",
       " '77',\n",
       " '90',\n",
       " '79',\n",
       " '32',\n",
       " '91',\n",
       " '95',\n",
       " '93',\n",
       " '-',\n",
       " '-',\n",
       " '42',\n",
       " '99',\n",
       " '-']"
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Last_Week_Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "6bc9e58c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(Last_Week_Rank))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80219fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "8ed02e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Peak_rank=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "id": "c3948ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[2]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[3]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[4]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[5]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[6]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[7]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[8]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[9]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[10]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[11]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[12]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[13]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[14]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[15]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[16]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[17]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[18]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[19]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[20]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[21]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[22]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[23]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[24]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[25]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[26]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[27]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "\n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[28]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[29]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[30]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[31]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[32]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[33]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[34]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[35]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[36]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[37]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[38]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[39]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[40]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[41]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[42]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[43]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[44]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[45]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[46]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[47]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[48]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[49]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[50]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[51]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[52]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[53]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[54]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[55]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[56]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[57]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[58]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[59]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[60]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[61]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[62]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[63]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[64]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[65]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[66]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[67]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[68]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[69]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[70]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[71]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[72]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[73]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[74]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[75]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[76]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[77]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[78]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[79]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[80]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[81]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[82]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[83]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[84]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[85]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[86]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[87]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[88]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[89]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[90]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[91]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[92]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[93]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[94]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[95]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[96]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[97]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[98]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[99]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[100]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[101]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[102]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[103]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[104]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[105]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[103]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[104]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[106]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[107]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "    \n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[108]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_rank_tags[0:100]:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "id": "0ccde3bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " '10',\n",
       " '1',\n",
       " '1',\n",
       " '13',\n",
       " '14',\n",
       " '15',\n",
       " '1',\n",
       " '3',\n",
       " '6',\n",
       " '5',\n",
       " '20',\n",
       " '21',\n",
       " '1',\n",
       " '4',\n",
       " '14',\n",
       " '23',\n",
       " '26',\n",
       " '10',\n",
       " '12',\n",
       " '9',\n",
       " '1',\n",
       " '1',\n",
       " '32',\n",
       " '33',\n",
       " '9',\n",
       " '5',\n",
       " '1',\n",
       " '8',\n",
       " '3',\n",
       " '13',\n",
       " '16',\n",
       " '41',\n",
       " '6',\n",
       " '33',\n",
       " '4',\n",
       " '45',\n",
       " '8',\n",
       " '6',\n",
       " '48',\n",
       " '22',\n",
       " '28',\n",
       " '22',\n",
       " '29',\n",
       " '24',\n",
       " '54',\n",
       " '21',\n",
       " '53',\n",
       " '38',\n",
       " '35',\n",
       " '31',\n",
       " '32',\n",
       " '33',\n",
       " '41',\n",
       " '10',\n",
       " '50',\n",
       " '65',\n",
       " '22',\n",
       " '19',\n",
       " '47',\n",
       " '57',\n",
       " '46',\n",
       " '26',\n",
       " '8',\n",
       " '15',\n",
       " '5',\n",
       " '40',\n",
       " '44',\n",
       " '58',\n",
       " '30',\n",
       " '55',\n",
       " '54',\n",
       " '42',\n",
       " '67',\n",
       " '44',\n",
       " '8',\n",
       " '63',\n",
       " '74',\n",
       " '37',\n",
       " '51',\n",
       " '69',\n",
       " '79',\n",
       " '32',\n",
       " '72',\n",
       " '82',\n",
       " '63',\n",
       " '95',\n",
       " '82',\n",
       " '63',\n",
       " '78',\n",
       " '42',\n",
       " '95']"
      ]
     },
     "execution_count": 513,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Peak_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "ec549d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(Peak_rank))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "id": "453ebad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Weeks_on_board = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "id": "7aacbc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[2]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[3]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[4]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[5]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[6]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[7]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[8]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[9]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[10]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[11]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[12]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[13]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[14]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[15]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[16]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[17]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[18]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[19]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[20]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[21]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[22]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[23]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[24]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[25]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[26]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[27]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[28]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[29]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[30]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[31]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[32]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[33]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[34]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[35]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[36]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[37]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[38]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[39]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[40]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[41]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[42]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[43]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[44]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[45]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[46]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[47]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[48]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[49]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[50]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[51]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[52]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[53]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[54]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[55]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[56]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[57]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[58]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[59]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[60]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[61]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[62]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[63]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[64]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[65]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[66]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[67]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[68]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[69]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[70]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[71]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[72]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[73]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[74]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[75]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "\n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[76]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[77]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[78]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[79]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[80]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[81]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[82]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[83]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[84]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[85]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[86]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[87]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[88]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[89]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[90]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[91]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[92]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[93]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[94]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[95]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[96]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[97]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[98]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[99]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[100]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[101]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[102]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[103]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[104]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[105]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[106]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[107]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[108]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[109]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)\n",
    "    \n",
    "Weeks_on_board_tag=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[110]/ul/li[4]/ul/li[6]/span')\n",
    "for i in Weeks_on_board_tag[0:100]:\n",
    "    weeks_on_board=i.text\n",
    "    Weeks_on_board.append(weeks_on_board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "id": "f7174a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(Weeks_on_board))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f493a0",
   "metadata": {},
   "source": [
    "# Q7 Scrape the details of Data science recruiters from naukri.com.\n",
    "Url = https://www.naukri.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15b84f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8069d8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.naukri.com/data-scientist-recruiters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb637ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "designation=driver.find_element(By.CLASS_NAME,'sugInp ')\n",
    "designation.send_keys('Data science')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d0f85038",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.XPATH,'/html/body/div[2]/div[2]/div[2]/div/form/div[1]/button')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3cef2930",
   "metadata": {},
   "outputs": [],
   "source": [
    "Name =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4da8fd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping Name from the given page\n",
    "Name_tags=driver.find_elements(By.XPATH,'//span[@class=\"fl ellipsis\"]')\n",
    "for i in Name_tags:\n",
    "    name=i.text\n",
    "    Name.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3be27666",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Aakash Harit',\n",
       " 'shravan Kumar Gaddam',\n",
       " 'MARSIAN Technologies LLP',\n",
       " 'Anik Agrawal',\n",
       " 'subhas patel',\n",
       " 'Abhishek - Only Analytics Hiring - India and',\n",
       " 'Institute for Financial Management and Resear',\n",
       " 'Balu Ramesh',\n",
       " 'Asif Lucknowi',\n",
       " 'InstaFinancials',\n",
       " 'Kalpana Dumpala',\n",
       " 'Mubarak',\n",
       " 'Kushal Rastogi',\n",
       " 'Mahesh Babu Channa',\n",
       " 'Vaishnavi Kudalkar',\n",
       " 'Priyanka Akiri',\n",
       " 'Kapil Devang',\n",
       " 'Sakshi Chhikara',\n",
       " 'Ruchi Dhote',\n",
       " 'Manisha Yadav',\n",
       " 'Riya Rajesh',\n",
       " 'Rashmi Bhattacharjee',\n",
       " 'Faizan Kareem',\n",
       " 'Rithika dadwal',\n",
       " 'Sandhya Khandagale',\n",
       " 'Shaun Rao',\n",
       " 'Azahar Shaikh',\n",
       " 'Manas',\n",
       " 'kumar',\n",
       " 'Sunil Vedula',\n",
       " 'Rajat Kumar',\n",
       " 'Dhruv Dev Dubey',\n",
       " 'Jayanth N',\n",
       " 'Avodha',\n",
       " 'Priya Khare',\n",
       " 'Amit Sharma',\n",
       " 'Kanan',\n",
       " 'Shashikant Chaudhary',\n",
       " 'Brad',\n",
       " 'Rutuja Pawar',\n",
       " 'Madhusudhan Sridhar',\n",
       " 'Ankit Sinha',\n",
       " 'Gaurav Chouhan',\n",
       " 'Rashi Kacker',\n",
       " 'Ashwini',\n",
       " 'Balaji Kolli',\n",
       " 'Rajani Nagaraj',\n",
       " 'ROHIT Kumar',\n",
       " 'Amir Chowdhury',\n",
       " 'SREEDHAR']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "800b8869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "print(len(Name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "159e8c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "Designation = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e0d91ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping Designation from the given page\n",
    "Designation_tags=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis clr\"]')\n",
    "for i in Designation_tags:\n",
    "    designation=i.text\n",
    "    Designation.append(designation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a47de796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HR Manager',\n",
       " 'Company Recruiter',\n",
       " 'Company HR',\n",
       " 'Company Recruiter',\n",
       " 'Founder CEO',\n",
       " 'Recruitment Lead Consultant',\n",
       " 'Programme Manager',\n",
       " 'HR Administrator',\n",
       " 'Director',\n",
       " 'Human Resource',\n",
       " 'Executive Hiring',\n",
       " 'Company HR',\n",
       " 'Company HR',\n",
       " 'HR Team Lead',\n",
       " 'HR Executive',\n",
       " 'HR Manager',\n",
       " 'HR Manager',\n",
       " 'Assistant Manager HR',\n",
       " 'Senior Executive Talent Acquisition',\n",
       " 'HR Executive',\n",
       " 'Manager Talent Acquisition',\n",
       " 'HR Head',\n",
       " 'HR MANAGER',\n",
       " 'HR Recruiter',\n",
       " 'HR Recruiter',\n",
       " 'Manager Human Resources',\n",
       " 'Company Recruiter',\n",
       " 'Lead Talent acquisition',\n",
       " 'Proprietor',\n",
       " 'CEO',\n",
       " 'Founder CEO',\n",
       " 'Company Recruitment Head',\n",
       " 'Project Manager',\n",
       " 'Business Development Associate',\n",
       " 'Senior Manager',\n",
       " 'Consultant',\n",
       " 'senior technology instructor',\n",
       " 'HR Recruiter/HR Excutive',\n",
       " 'Manager, Technical Recruiting',\n",
       " 'Technical Recruiter',\n",
       " 'Erp Implementer',\n",
       " 'Head Analytics',\n",
       " 'Chief Technical Officer',\n",
       " 'Sr Product Manager',\n",
       " 'Director Global Delivery',\n",
       " 'Co Founder',\n",
       " 'HR Manager',\n",
       " 'Architect',\n",
       " 'Managing Partner',\n",
       " 'Recruitment Consultant']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Designation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bc5787e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "print(len(Designation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "7bf9892e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Company = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "6b044f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping Company from the given page\n",
    "Company_tags=driver.find_elements(By.XPATH,'/html/body/div[3]/div/div[2]/div/div[2]/div[1]/div[1]/div[1]/div[1]/p/a[2]')\n",
    "for i in Company_tags:\n",
    "    company=i.text\n",
    "    Company.append(company)\n",
    "    \n",
    "Company_tags=driver.find_elements(By.XPATH,'/html/body/div[3]/div/div[2]/div/div[2]/div[1]/div[2]/div[1]/div[1]/p/a[2]')\n",
    "for i in Company_tags:\n",
    "    company=i.text\n",
    "    Company.append(company)\n",
    "    \n",
    "Company_tags=driver.find_elements(By.XPATH,'/html/body/div[3]/div/div[2]/div/div[2]/div[2]/div[1]/div[1]/div[1]/p/a[2]')\n",
    "for i in Company_tags:\n",
    "    company=i.text\n",
    "    Company.append(company)\n",
    "    \n",
    "Company_tags=driver.find_elements(By.XPATH,'/html/body/div[3]/div/div[2]/div/div[2]/div[2]/div[2]/div[1]/div[1]/p/a[2]')\n",
    "for i in Company_tags:\n",
    "    company=i.text\n",
    "    Company.append(company)\n",
    "    \n",
    "Company_tags=driver.find_elements(By.XPATH,'/html/body/div[3]/div/div[2]/div/div[2]/div[3]/div[1]/div[1]/div[1]/p/a[2]')\n",
    "for i in Company_tags:\n",
    "    company=i.text\n",
    "    Company.append(company)\n",
    "    \n",
    "Company_tags=driver.find_elements(By.XPATH,'/html/body/div[3]/div/div[2]/div/div[2]/div[3]/div[1]/div[1]/div[1]/p/a[2]')\n",
    "for i in Company_tags:\n",
    "    company=i.text\n",
    "    Company.append(company)\n",
    "    \n",
    "Company_tags=driver.find_elements(By.XPATH,'/html/body/div[3]/div/div[2]/div/div[2]/div[3]/div[2]/div[1]/div[1]/p/a[2]')\n",
    "for i in Company_tags:\n",
    "    company=i.text\n",
    "    Company.append(company)\n",
    "    \n",
    "Company_tags=driver.find_elements(By.XPATH,'/html/body/div[3]/div/div[2]/div/div[2]/div[4]/div[1]/div[1]/div[1]/p/a[2]')\n",
    "for i in Company_tags:\n",
    "    company=i.text\n",
    "    Company.append(company)\n",
    "    \n",
    "Company_tags=driver.find_elements(By.XPATH,'/html/body/div[3]/div/div[2]/div/div[2]/div[4]/div[2]/div[1]/div[1]/p/a[2]')\n",
    "for i in Company_tags:\n",
    "    company=i.text\n",
    "    Company.append(company)\n",
    "    \n",
    "Company_tags=driver.find_elements(By.XPATH,'/html/body/div[3]/div/div[2]/div/div[2]/div[5]/div[1]/div[1]/div[1]/p/a[2]')\n",
    "for i in Company_tags:\n",
    "    company=i.text\n",
    "    Company.append(company)\n",
    "    \n",
    "Company_tags=driver.find_elements(By.XPATH,'/html/body/div[3]/div/div[2]/div/div[2]/div[5]/div[2]/div[1]/div[1]/p/a[2]')\n",
    "for i in Company_tags:\n",
    "    company=i.text\n",
    "    Company.append(company)\n",
    "    \n",
    "Company_tags=driver.find_elements(By.XPATH,'/html/body/div[3]/div/div[2]/div/div[2]/div[6]/div[1]/div[1]/div[1]/p/a[2]')\n",
    "for i in Company_tags:\n",
    "    company=i.text\n",
    "    Company.append(company)\n",
    "    \n",
    "Company_tags=driver.find_elements(By.XPATH,'/html/body/div[3]/div/div[2]/div/div[2]/div[6]/div[2]/div[1]/div[1]/p/a[2]')\n",
    "for i in Company_tags:\n",
    "    company=i.text\n",
    "    Company.append(company)\n",
    "    \n",
    "Company_tags=driver.find_elements(By.XPATH,'/html/body/div[3]/div/div[2]/div/div[2]/div[7]/div[1]/div[1]/div[1]/p/a[2]')\n",
    "for i in Company_tags:\n",
    "    company=i.text\n",
    "    Company.append(company)\n",
    "    \n",
    "Company_tags=driver.find_elements(By.XPATH,'/html/body/div[3]/div/div[2]/div/div[2]/div[7]/div[2]/div[1]/div[1]/p/a[2]')\n",
    "for i in Company_tags:\n",
    "    company=i.text\n",
    "    Company.append(company)\n",
    "    \n",
    "Company_tags=driver.find_elements(By.XPATH,'/html/body/div[3]/div/div[2]/div/div[2]/div[8]/div[1]/div[1]/div[1]/p/a[2]')\n",
    "for i in Company_tags:\n",
    "    company=i.text\n",
    "    Company.append(company)\n",
    "    \n",
    "Company_tags=driver.find_elements(By.XPATH,'/html/body/div[3]/div/div[2]/div/div[2]/div[8]/div[2]/div[1]/div[1]/p/a[2]')\n",
    "for i in Company_tags:\n",
    "    company=i.text\n",
    "    Company.append(company)\n",
    "    \n",
    "Company_tags=driver.find_elements(By.XPATH,'/html/body/div[3]/div/div[2]/div/div[2]/div[9]/div[1]/div[1]/div[1]/p/a[2]')\n",
    "for i in Company_tags:\n",
    "    company=i.text\n",
    "    Company.append(company)\n",
    "    \n",
    "Company_tags=driver.find_elements(By.XPATH,'/html/body/div[3]/div/div[2]/div/div[2]/div[9]/div[2]/div[1]/div[1]/p/a[2]')\n",
    "for i in Company_tags:\n",
    "    company=i.text\n",
    "    Company.append(company)\n",
    "    \n",
    "Company_tags=driver.find_elements(By.XPATH,'/html/body/div[3]/div/div[2]/div/div[2]/div[10]/div[1]/div[1]/div[1]/p/a[2]')\n",
    "for i in Company_tags:\n",
    "    company=i.text\n",
    "    Company.append(company)\n",
    "    \n",
    "Company_tags=driver.find_elements(By.XPATH,'/html/body/div[3]/div/div[2]/div/div[2]/div[10]/div[2]/div[1]/div[1]/p/a[2]')\n",
    "for i in Company_tags:\n",
    "    company=i.text\n",
    "    Company.append(company)\n",
    "    \n",
    "Company_tags=driver.find_elements(By.XPATH,'/html/body/div[3]/div/div[2]/div/div[2]/div[11]/div[1]/div[1]/div[1]/p/a[2]')\n",
    "for i in Company_tags:\n",
    "    company=i.text\n",
    "    Company.append(company)\n",
    "    \n",
    "Company_tags=driver.find_elements(By.XPATH,'/html/body/div[3]/div/div[2]/div/div[2]/div[11]/div[2]/div[1]/div[1]/p/a[2]')\n",
    "for i in Company_tags:\n",
    "    company=i.text\n",
    "    Company.append(company)\n",
    "    \n",
    "Company_tags=driver.find_elements(By.XPATH,'/html/body/div[3]/div/div[2]/div/div[2]/div[12]/div[1]/div[1]/div[1]/p/a[2]')\n",
    "for i in Company_tags:\n",
    "    company=i.text\n",
    "    Company.append(company)\n",
    "    \n",
    "Company_tags=driver.find_elements(By.XPATH,'/html/body/div[3]/div/div[2]/div/div[2]/div[12]/div[2]/div[1]/div[1]/p/a[2]')\n",
    "for i in Company_tags:\n",
    "    company=i.text\n",
    "    Company.append(company)\n",
    "    \n",
    "Company_tags=driver.find_elements(By.XPATH,'/html/body/div[3]/div/div[2]/div/div[2]/div[13]/div[1]/div[1]/div[1]/p/a[2]')\n",
    "for i in Company_tags:\n",
    "    company=i.text\n",
    "    Company.append(company)\n",
    "    \n",
    "Company_tags=driver.find_elements(By.XPATH,'/html/body/div[3]/div/div[2]/div/div[2]/div[13]/div[2]/div[1]/div[1]/p/a[2]')\n",
    "for i in Company_tags:\n",
    "    company=i.text\n",
    "    Company.append(company)\n",
    "    \n",
    "Company_tags=driver.find_elements(By.XPATH,'/html/body/div[3]/div/div[2]/div/div[2]/div[14]/div[1]/div[1]/div[1]/p/a[2]')\n",
    "for i in Company_tags:\n",
    "    company=i.text\n",
    "    Company.append(company)\n",
    "    \n",
    "Company_tags=driver.find_elements(By.XPATH,'/html/body/div[3]/div/div[2]/div/div[2]/div[14]/div[2]/div[1]/div[1]/p/a[2]')\n",
    "for i in Company_tags:\n",
    "    company=i.text\n",
    "    Company.append(company)\n",
    "    \n",
    "Company_tags=driver.find_elements(By.XPATH,'/html/body/div[3]/div/div[2]/div/div[2]/div[15]/div[1]/div[1]/div[1]/p/a[2]')\n",
    "for i in Company_tags:\n",
    "    company=i.text\n",
    "    Company.append(company)\n",
    "    \n",
    "Company_tags=driver.find_elements(By.XPATH,'/html/body/div[3]/div/div[2]/div/div[2]/div[15]/div[2]/div[1]/div[1]/p/a[2]')\n",
    "for i in Company_tags:\n",
    "    company=i.text\n",
    "    Company.append(company)\n",
    "    \n",
    "Company_tags=driver.find_elements(By.XPATH,'/html/body/div[3]/div/div[2]/div/div[2]/div[16]/div[1]/div[1]/div[1]/p/a[2]')\n",
    "for i in Company_tags:\n",
    "    company=i.text\n",
    "    Company.append(company)\n",
    "    \n",
    "Company_tags=driver.find_elements(By.XPATH,'/html/body/div[3]/div/div[2]/div/div[2]/div[16]/div[2]/div[1]/div[1]/p/a[2]')\n",
    "for i in Company_tags:\n",
    "    company=i.text\n",
    "    Company.append(company)\n",
    "    \n",
    "Company_tags=driver.find_elements(By.XPATH,'/html/body/div[3]/div/div[2]/div/div[2]/div[17]/div[1]/div[1]/div[1]/p/a[2]')\n",
    "for i in Company_tags:\n",
    "    company=i.text\n",
    "    Company.append(company)\n",
    "    \n",
    "    \n",
    "Company_tags=driver.find_elements(By.XPATH,'/html/body/div[3]/div/div[2]/div/div[2]/div[17]/div[2]/div[1]/div[1]/p/a[2]')\n",
    "for i in Company_tags:\n",
    "    company=i.text\n",
    "    Company.append(company)\n",
    "    \n",
    "Company_tags=driver.find_elements(By.XPATH,'/html/body/div[3]/div/div[2]/div/div[2]/div[18]/div[1]/div[1]/div[1]/p/a[2]')\n",
    "for i in Company_tags:\n",
    "    company=i.text\n",
    "    Company.append(company)\n",
    "    \n",
    "Company_tags=driver.find_elements(By.XPATH,'/html/body/div[3]/div/div[2]/div/div[2]/div[18]/div[2]/div[1]/div[1]/p/a[2]')\n",
    "for i in Company_tags:\n",
    "    company=i.text\n",
    "    Company.append(company)\n",
    "    \n",
    "Company_tags=driver.find_elements(By.XPATH,'/html/body/div[3]/div/div[2]/div/div[2]/div[19]/div[1]/div[1]/div[1]/p/a[2]')\n",
    "for i in Company_tags:\n",
    "    company=i.text\n",
    "    Company.append(company)\n",
    "    \n",
    "Company_tags=driver.find_elements(By.XPATH,'/html/body/div[3]/div/div[2]/div/div[2]/div[19]/div[2]/div[1]/div[1]/p/a[2]')\n",
    "for i in Company_tags:\n",
    "    company=i.text\n",
    "    Company.append(company)\n",
    "    \n",
    "Company_tags=driver.find_elements(By.XPATH,'/html/body/div[3]/div/div[2]/div/div[2]/div[20]/div[1]/div[1]/div[1]/p/a[2]')\n",
    "for i in Company_tags:\n",
    "    company=i.text\n",
    "    Company.append(company)\n",
    "    \n",
    "Company_tags=driver.find_elements(By.XPATH,'/html/body/div[3]/div/div[2]/div/div[2]/div[20]/div[2]/div[1]/div[1]/p/a[2]')\n",
    "for i in Company_tags:\n",
    "    company=i.text\n",
    "    Company.append(company)\n",
    "    \n",
    "Company_tags=driver.find_elements(By.XPATH,'/html/body/div[3]/div/div[2]/div/div[2]/div[21]/div[1]/div[1]/div[1]/p/a[2]')\n",
    "for i in Company_tags:\n",
    "    company=i.text\n",
    "    Company.append(company)\n",
    "    \n",
    "Company_tags=driver.find_elements(By.XPATH,'/html/body/div[3]/div/div[2]/div/div[2]/div[21]/div[2]/div[1]/div[1]/p/a[2]')\n",
    "for i in Company_tags:\n",
    "    company=i.text\n",
    "    Company.append(company)\n",
    "    \n",
    "Company_tags=driver.find_elements(By.XPATH,'/html/body/div[3]/div/div[2]/div/div[2]/div[22]/div[1]/div[1]/div[1]/p/a[2]')\n",
    "for i in Company_tags:\n",
    "    company=i.text\n",
    "    Company.append(company)\n",
    "    \n",
    "Company_tags=driver.find_elements(By.XPATH,'/html/body/div[3]/div/div[2]/div/div[2]/div[22]/div[2]/div[1]/div[1]/p/a[2]')\n",
    "for i in Company_tags:\n",
    "    company=i.text\n",
    "    Company.append(company)\n",
    "    \n",
    "Company_tags=driver.find_elements(By.XPATH,'/html/body/div[3]/div/div[2]/div/div[2]/div[23]/div[1]/div[1]/div[1]/p/a[2]')\n",
    "for i in Company_tags:\n",
    "    company=i.text\n",
    "    Company.append(company)\n",
    "    \n",
    "Company_tags=driver.find_elements(By.XPATH,'/html/body/div[3]/div/div[2]/div/div[2]/div[23]/div[2]/div[1]/div[1]/p/a[2]')\n",
    "for i in Company_tags:\n",
    "    company=i.text\n",
    "    Company.append(company)\n",
    "    \n",
    "Company_tags=driver.find_elements(By.XPATH,'/html/body/div[3]/div/div[2]/div/div[2]/div[24]/div[1]/div[1]/div[1]/p/a[2]')\n",
    "for i in Company_tags:\n",
    "    company=i.text\n",
    "    Company.append(company)\n",
    "    \n",
    "Company_tags=driver.find_elements(By.XPATH,'/html/body/div[3]/div/div[2]/div/div[2]/div[24]/div[2]/div[1]/div[1]/p/a[2]')\n",
    "for i in Company_tags:\n",
    "    company=i.text\n",
    "    Company.append(company)\n",
    "    \n",
    "Company_tags=driver.find_elements(By.XPATH,'/html/body/div[3]/div/div[2]/div/div[2]/div[25]/div[1]/div[1]/div[1]/p/a[2]')\n",
    "for i in Company_tags:\n",
    "    company=i.text\n",
    "    Company.append(company)\n",
    "    \n",
    "Company_tags=driver.find_elements(By.XPATH,'/html/body/div[3]/div/div[2]/div/div[2]/div[25]/div[2]/div[1]/div[1]/p/a[2]')\n",
    "for i in Company_tags:\n",
    "    company=i.text\n",
    "    Company.append(company)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "87e4039e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Science Network',\n",
       " 'Shore Infotech India Pvt. Ltd',\n",
       " 'MARSIAN Technologies LLP',\n",
       " 'Enerlytics Software Solutions Pvt Ltd',\n",
       " 'LibraryXProject',\n",
       " 'LibraryXProject',\n",
       " 'Apidel Technologies Division of Transpower',\n",
       " 'IFMR',\n",
       " 'Techvantage Systems Pvt Ltd',\n",
       " 'Weupskill- Live Wire India',\n",
       " 'CBL Data Science Private Limited',\n",
       " 'Innominds Software',\n",
       " 'MoneyTap',\n",
       " 'QuantMagnum Technologies Pvt. Ltd.',\n",
       " 'SocialPrachar.com',\n",
       " 'Codeachive learning',\n",
       " 'Infinitive Software Solutions',\n",
       " 'BISP Solutions',\n",
       " 'BIZ INFOTECNO PRIVATE LIMITED',\n",
       " 'Bristlecone India Ltd',\n",
       " 'Easi Tax',\n",
       " 'Novelworx Digital Solutions',\n",
       " 'AXESTRACK SOFTWARE SOLUTIONS PRIVATE...',\n",
       " 'FirstTech Consaltants Pvt.Ltd',\n",
       " 'Affine Analytics',\n",
       " 'Compumatrice Multimedia Pvt Ltd',\n",
       " 'Exela Technologies',\n",
       " 'NEAL ANALYTICS SERVICES PVT LTD',\n",
       " 'Autumn Leaf Consulting Services Private...',\n",
       " 'trainin',\n",
       " 'Nanoprecise Sci Corp',\n",
       " 'R.S Consultancy &amp; Services',\n",
       " 'Confidential',\n",
       " 'Dollarbird Information Services Pvt, Ltd',\n",
       " 'Nikitha Palaparthi',\n",
       " 'Independent Consultant',\n",
       " 'ASCO consulting',\n",
       " 'NY INST',\n",
       " '3D India Staffing Research &amp; Consulting...',\n",
       " 'O.C. Tanner',\n",
       " 'Demand Matrix',\n",
       " 'MADHUSUDHAN SRIDHAR',\n",
       " 'Suntech Global',\n",
       " 'Strategic Consulting Lab',\n",
       " 'Impel Labs Pvt. Ltd.',\n",
       " 'MRP Advisers',\n",
       " 'Saras Solutions India Pvt Ltd',\n",
       " 'WildJasmine',\n",
       " 'LNT Private Limited',\n",
       " 'Granular.ai',\n",
       " 'JOBSMILL BUSINESS SOLUTIONS PRIVATE LIMITED']"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "11461264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n"
     ]
    }
   ],
   "source": [
    "print(len(Company))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "69e12b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "Location = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ba7ffab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping Location from the given page\n",
    "location_tags=driver.find_elements(By.XPATH,'//small[@class=\"ellipsis\"]')\n",
    "for i in location_tags:\n",
    "    location=i.text\n",
    "    Location.append(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e4ab1375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Delhi',\n",
       " 'Hyderabad / Secunderabad',\n",
       " 'Pune',\n",
       " 'Ahmedabad',\n",
       " 'UK - (london)',\n",
       " 'Vadodara / Baroda',\n",
       " 'Chennai',\n",
       " 'Trivandrum',\n",
       " 'Indore',\n",
       " 'Bengaluru / Bangalore',\n",
       " 'Hyderabad / Secunderabad',\n",
       " 'Bengaluru / Bangalore',\n",
       " 'Mumbai',\n",
       " 'Hyderabad / Secunderabad',\n",
       " 'Mumbai',\n",
       " 'Hyderabad',\n",
       " 'Bhopal',\n",
       " 'Chandigarh',\n",
       " 'Pune',\n",
       " 'Navi Mumbai',\n",
       " 'Cochin',\n",
       " 'Delhi',\n",
       " 'Hyderabad / Secunderabad',\n",
       " 'Pune',\n",
       " 'Pune',\n",
       " 'Pune',\n",
       " 'Pune',\n",
       " 'Bengaluru / Bangalore',\n",
       " 'Bengaluru / Bangalore',\n",
       " 'Delhi',\n",
       " 'Bengaluru / Bangalore',\n",
       " 'Mysoru / Mysore',\n",
       " 'Hyderabad / Secunderabad',\n",
       " 'Bengaluru / Bangalore',\n",
       " 'New Delhi',\n",
       " 'Chennai',\n",
       " 'Aligarh',\n",
       " 'Salt Lake City',\n",
       " 'Pune',\n",
       " 'Bengaluru / Bangalore',\n",
       " 'Mumbai',\n",
       " 'Indore',\n",
       " 'Bengaluru / Bangalore',\n",
       " 'MYSORE',\n",
       " 'Hyderabad / Secunderabad',\n",
       " 'Bengaluru / Bangalore',\n",
       " 'Mumbai',\n",
       " 'Hyderabad / Secunderabad']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "18eed2d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n"
     ]
    }
   ],
   "source": [
    "print(len(Location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ba99704b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Skills_they_hire_for = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3dd20d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping Skills_they_hire_for from the given page\n",
    "Skills_tags=driver.find_elements(By.XPATH,'//div[@class=\"hireSec highlightable\"]')\n",
    "for i in Skills_tags:\n",
    "    skill=i.text\n",
    "    Skills_they_hire_for.append(skill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "06fb49fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Classic ASP Developer, Internet Marketing Professional, Data Science SME, Content Writers, SEO Professional, Revenue Professional',\n",
       " '.Net, Java, Data Science, Linux Administration, Sql Server Development, Winforms, Wcf Services, Wpf, Telecom Engineering, Technical Management, Software',\n",
       " 'Data Science, Artificial Intelligence, Machine Learning, Business Analytics, Deep Learning, statistics, Data Analytics, Data Analysis, support vector machine',\n",
       " 'Mean Stack, javascript, angularjs, mongodb, Web Services, rest, express, Node.js, Big Data, iot, Data Science, Cloud Computing, saas, Aws',\n",
       " 'Hadoop, Spark, Digital Strategy, Data Architecture, Command Center, Cdp, Dmp, Kafka, Data Science, Data Analysis, Big Data Analytics, Real Time Analysis, SQL',\n",
       " 'Analytics, Business Intelligence, Business Analytics, Predictive Modeling, Predictive Analytics, Data Science, Data Analysis, Data Analytics, Big Data, Big',\n",
       " 'Data Science',\n",
       " 'Machine Learning, algorithms, Go Getter, Computer Science, spark, Big Data, hdfs, sql, cassandra, hadoop, python, scala, java, Data Science, Front End',\n",
       " 'Technical Training, Software Development, Presentation Skills, B.tech, M.tech, B.e., mca, msc, Computer Science, freshers, jobs in indore, Data Science, itil',\n",
       " 'Software Development, It Sales, Account Management, Data Analysis, Customer Service, Sr, Software Engineering, Mvc, Ajax, Asp.net, Html, C#, Javascript',\n",
       " 'Qa, Ui/ux, Java Developer, Java Architect, C++/qt, Php, Lamp, Api, J2ee, Java, Soa, Esb, Middleware, Bigdata Achitect, Hadoop Architect, Deep',\n",
       " 'Business Intelligence, Data Warehousing, Data Science, Business Analytics, Customer Support, Business Reporting, Bi',\n",
       " 'Office Administration, Hr Administration, telecalling, client relationship management, Client Acquisition, Sales, Reception, HR, Recruitment, Onboarding, Human',\n",
       " 'Social Media, digital media maketing, seo, smm, smo, sem, Content Wirting, social media marketing, social media manager, digital media marketing manager',\n",
       " 'Data Science, Python, Data Analytics',\n",
       " 'Oracle Dba, Data Science, Data Warehousing, ETL, Jupyter, Numpy, Data Transformation, Snowflake, Teradata, Python, Data Manipulation, Relational Databases',\n",
       " 'Big Data, Hadoop, Data Analytics, Data Science',\n",
       " 'React.js, Data Science, Java, Front End, Business Analytics, Backend, Tableau, Python, Qa Testing, Automation Testing',\n",
       " 'Qlikview, Qlik Sense, Microsoft Azure, Power Bi, Data Science, Machine Learning',\n",
       " 'Telecalling, Client Interaction, Marketing, Research, Web Development, Social Media Marketing, Data Entry Operation, Excel, Ms Office, Invoicing',\n",
       " 'Data Science',\n",
       " 'Corporate Sales, Software Development, Software Sales, Marketing, Creative Designing, Corporate Planning, Senior Management, Crm, Client Relationship',\n",
       " 'Data Analytics, Data Science, Machine Learning, Deep Learning, Nlp, Data Mining, Python, R, Database Administration, Text Mining',\n",
       " 'Data Science, Machine Learning, Python, R, Deep Learning, Big Data, Hadoop',\n",
       " 'Big Data, Data Science, Artificial Intelligence, Hadoop, Ui Development, Php, Freelancing, .Net, Software Testing, Sap, Leadership Hiring',\n",
       " 'Java, Net, Angularjs, Hr, Infrastructure, Management, Project Management, Business Analysis, Data Science, Information Technology, Technology',\n",
       " 'Data Science, Artificial Intelligence, Machine Learning, Data Analytics',\n",
       " 'Software Architecture, Vp Engineering, Product Management, analytics, Data Science, Node.js, Principal Engineer, Big Data, python, angularjs, React.js',\n",
       " 'Data Science, Hadoop, Rpas, Devops, Python, Aws, Teaching, Big Data',\n",
       " 'Signal Processing, Machine Learning, Neural Networks, Data Science, Predictive Analytics, Time Series Analysis, Data Visualization, Technical Leadership, Data',\n",
       " 'Web Technologies, Project Management, Software Architecture, Data Science, Object Oriented Programming, Computer Science, Electrical Engineering, Architecture',\n",
       " 'Server Administartion, Verilog, Vhdl, Digital Marketing, Market Research, Property Research, Legal, It And Non It Recruitment, Logistics, Supply Chain, Bfsi',\n",
       " 'Data Analytics, Managed Services, Team Leading, python, Machine Learning, Google Analytics, Dmp, Aws, Campaign Analytics, Digital Campaigns, Audience',\n",
       " 'Ethical Hacking, Security Operations Center, SOC, Managed Services, Data Science, Machine Learning, Artificial Intelligence, Operations Research, Education',\n",
       " 'Data Science, Artificial Intelligence, analytics, Business Intelligence, python, tableau, Power Bi, qlikview, sql, Data Warehousing, Data Visualization',\n",
       " 'Machine Learning, Artificial Intelligence, Data Science, Software Engineering, Software Development, Graduate Engineer Trainee, Fresher, Data Analytics, Java',\n",
       " 'C, C++, Artificial Intelligence, Python, Php, Web Development, Matlab, Data Science, Augmented Reality, C C++',\n",
       " 'Relationship Management, Retail Sales, Private Banking, Mutual Funds, NISM, Equity, Finance, Financial Products, Financial Services, Verbal, Written',\n",
       " 'Data Science, Software Engineering',\n",
       " 'Data Science, Big Data Analytics, Digital Marketing, Content Writing, Ui Development, Database Development, Qa Automation, Python, Project Management',\n",
       " 'Data Science, Recruitment, Salary',\n",
       " 'B.Tech, Tableau, Statistics, R, Analytics, Time Series, Data Science, Business Solutions, SQL, Technical Skills, SSAS, SQL Server, Analysis Services, Qlikview',\n",
       " 'Software Development, Business Intelligence, Big Data Analytics, Database Administration, Data Science, Microsoft Azure, Spark, Cassandra, Object Oriented',\n",
       " 'Data Science, Node.js, Angularjs',\n",
       " 'Data Science, Media Marketing, Resource Planning, Managed Services, Display Advertising, Machine Learning, Python, Etl, Sql',\n",
       " 'Data Analysis, Learning, Data Science, Computer Science, Communication Skills',\n",
       " 'Java, Hadoop, R, Machine Learning, Spark, Flume, Hdfs, Data Mining, Sas, Big, Data Science, Cloudera, Impala, Bigdata',\n",
       " 'Software Development, Core Java, Unit Testing, Customer Experience, Problem Solving, Communication Skills, Mysql, Data Science, Sales Management, Analytics',\n",
       " 'Machine Learning, Data Science, Product Management, New Product, Data Analysis, Computer Vision, Deep Learning, Python, Remote Sensing',\n",
       " 'Data Science, Machine Learning, Big Data Analytics, Spark, Python, R, Networking, Network Engineering, Placement, Training, Sql, Marketing, Mainframes, All']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Skills_they_hire_for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2c4fe051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "print(len(Skills_they_hire_for))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b725a0",
   "metadata": {},
   "source": [
    "# Q8. Scrape the details of Highest selling novels.\n",
    "Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey\u0002compare/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "c4d66bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "f0ed2061",
   "metadata": {},
   "outputs": [],
   "source": [
    "Book_name = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "6fef8ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping Book_name from the given page\n",
    "Book_name_tags=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"][1]/tbody/tr/td[2]')\n",
    "for i in Book_name_tags:\n",
    "    Book=i.text\n",
    "    Book_name.append(Book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "b19188f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Da Vinci Code,The',\n",
       " 'Harry Potter and the Deathly Hallows',\n",
       " \"Harry Potter and the Philosopher's Stone\",\n",
       " 'Harry Potter and the Order of the Phoenix',\n",
       " 'Fifty Shades of Grey',\n",
       " 'Harry Potter and the Goblet of Fire',\n",
       " 'Harry Potter and the Chamber of Secrets',\n",
       " 'Harry Potter and the Prisoner of Azkaban',\n",
       " 'Angels and Demons',\n",
       " \"Harry Potter and the Half-blood Prince:Children's Edition\",\n",
       " 'Fifty Shades Darker',\n",
       " 'Twilight',\n",
       " 'Girl with the Dragon Tattoo,The:Millennium Trilogy',\n",
       " 'Fifty Shades Freed',\n",
       " 'Lost Symbol,The',\n",
       " 'New Moon',\n",
       " 'Deception Point',\n",
       " 'Eclipse',\n",
       " 'Lovely Bones,The',\n",
       " 'Curious Incident of the Dog in the Night-time,The',\n",
       " 'Digital Fortress',\n",
       " 'Short History of Nearly Everything,A',\n",
       " 'Girl Who Played with Fire,The:Millennium Trilogy',\n",
       " 'Breaking Dawn',\n",
       " 'Very Hungry Caterpillar,The:The Very Hungry Caterpillar',\n",
       " 'Gruffalo,The',\n",
       " \"Jamie's 30-Minute Meals\",\n",
       " 'Kite Runner,The',\n",
       " 'One Day',\n",
       " 'Thousand Splendid Suns,A',\n",
       " \"Girl Who Kicked the Hornets' Nest,The:Millennium Trilogy\",\n",
       " \"Time Traveler's Wife,The\",\n",
       " 'Atonement',\n",
       " \"Bridget Jones's Diary:A Novel\",\n",
       " 'World According to Clarkson,The',\n",
       " \"Captain Corelli's Mandolin\",\n",
       " 'Sound of Laughter,The',\n",
       " 'Life of Pi',\n",
       " 'Billy Connolly',\n",
       " 'Child Called It,A',\n",
       " \"Gruffalo's Child,The\",\n",
       " \"Angela's Ashes:A Memoir of a Childhood\",\n",
       " 'Birdsong',\n",
       " 'Northern Lights:His Dark Materials S.',\n",
       " 'Labyrinth',\n",
       " 'Harry Potter and the Half-blood Prince',\n",
       " 'Help,The',\n",
       " 'Man and Boy',\n",
       " 'Memoirs of a Geisha',\n",
       " \"No.1 Ladies' Detective Agency,The:No.1 Ladies' Detective Agency S.\",\n",
       " 'Island,The',\n",
       " 'PS, I Love You',\n",
       " 'You are What You Eat:The Plan That Will Change Your Life',\n",
       " 'Shadow of the Wind,The',\n",
       " 'Tales of Beedle the Bard,The',\n",
       " 'Broker,The',\n",
       " \"Dr. Atkins' New Diet Revolution:The No-hunger, Luxurious Weight Loss P\",\n",
       " 'Subtle Knife,The:His Dark Materials S.',\n",
       " 'Eats, Shoots and Leaves:The Zero Tolerance Approach to Punctuation',\n",
       " \"Delia's How to Cook:(Bk.1)\",\n",
       " 'Chocolat',\n",
       " 'Boy in the Striped Pyjamas,The',\n",
       " \"My Sister's Keeper\",\n",
       " 'Amber Spyglass,The:His Dark Materials S.',\n",
       " 'To Kill a Mockingbird',\n",
       " 'Men are from Mars, Women are from Venus:A Practical Guide for Improvin',\n",
       " 'Dear Fatty',\n",
       " 'Short History of Tractors in Ukrainian,A',\n",
       " 'Hannibal',\n",
       " 'Lord of the Rings,The',\n",
       " 'Stupid White Men:...and Other Sorry Excuses for the State of the Natio',\n",
       " 'Interpretation of Murder,The',\n",
       " 'Sharon Osbourne Extreme:My Autobiography',\n",
       " 'Alchemist,The:A Fable About Following Your Dream',\n",
       " \"At My Mother's Knee ...:and Other Low Joints\",\n",
       " 'Notes from a Small Island',\n",
       " 'Return of the Naked Chef,The',\n",
       " 'Bridget Jones: The Edge of Reason',\n",
       " \"Jamie's Italy\",\n",
       " 'I Can Make You Thin',\n",
       " 'Down Under',\n",
       " 'Summons,The',\n",
       " 'Small Island',\n",
       " 'Nigella Express',\n",
       " 'Brick Lane',\n",
       " \"Memory Keeper's Daughter,The\",\n",
       " 'Room on the Broom',\n",
       " 'About a Boy',\n",
       " 'My Booky Wook',\n",
       " 'God Delusion,The',\n",
       " '\"Beano\" Annual,The',\n",
       " 'White Teeth',\n",
       " 'House at Riverton,The',\n",
       " 'Book Thief,The',\n",
       " 'Nights of Rain and Stars',\n",
       " 'Ghost,The',\n",
       " 'Happy Days with the Naked Chef',\n",
       " 'Hunger Games,The:Hunger Games Trilogy',\n",
       " \"Lost Boy,The:A Foster Child's Search for the Love of a Family\",\n",
       " \"Jamie's Ministry of Food:Anyone Can Learn to Cook in 24 Hours\"]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Book_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "5ccc925b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(Book_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "86b725d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Author_name = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "dedbb6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping Author_name from the given page\n",
    "Author_name_tags=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"][1]/tbody/tr/td[3]')\n",
    "for i in Author_name_tags:\n",
    "    Author=i.text\n",
    "    Author_name.append(Author)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "3fd7e7aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Brown, Dan',\n",
       " 'Rowling, J.K.',\n",
       " 'Rowling, J.K.',\n",
       " 'Rowling, J.K.',\n",
       " 'James, E. L.',\n",
       " 'Rowling, J.K.',\n",
       " 'Rowling, J.K.',\n",
       " 'Rowling, J.K.',\n",
       " 'Brown, Dan',\n",
       " 'Rowling, J.K.',\n",
       " 'James, E. L.',\n",
       " 'Meyer, Stephenie',\n",
       " 'Larsson, Stieg',\n",
       " 'James, E. L.',\n",
       " 'Brown, Dan',\n",
       " 'Meyer, Stephenie',\n",
       " 'Brown, Dan',\n",
       " 'Meyer, Stephenie',\n",
       " 'Sebold, Alice',\n",
       " 'Haddon, Mark',\n",
       " 'Brown, Dan',\n",
       " 'Bryson, Bill',\n",
       " 'Larsson, Stieg',\n",
       " 'Meyer, Stephenie',\n",
       " 'Carle, Eric',\n",
       " 'Donaldson, Julia',\n",
       " 'Oliver, Jamie',\n",
       " 'Hosseini, Khaled',\n",
       " 'Nicholls, David',\n",
       " 'Hosseini, Khaled',\n",
       " 'Larsson, Stieg',\n",
       " 'Niffenegger, Audrey',\n",
       " 'McEwan, Ian',\n",
       " 'Fielding, Helen',\n",
       " 'Clarkson, Jeremy',\n",
       " 'Bernieres, Louis de',\n",
       " 'Kay, Peter',\n",
       " 'Martel, Yann',\n",
       " 'Stephenson, Pamela',\n",
       " 'Pelzer, Dave',\n",
       " 'Donaldson, Julia',\n",
       " 'McCourt, Frank',\n",
       " 'Faulks, Sebastian',\n",
       " 'Pullman, Philip',\n",
       " 'Mosse, Kate',\n",
       " 'Rowling, J.K.',\n",
       " 'Stockett, Kathryn',\n",
       " 'Parsons, Tony',\n",
       " 'Golden, Arthur',\n",
       " 'McCall Smith, Alexander',\n",
       " 'Hislop, Victoria',\n",
       " 'Ahern, Cecelia',\n",
       " 'McKeith, Gillian',\n",
       " 'Zafon, Carlos Ruiz',\n",
       " 'Rowling, J.K.',\n",
       " 'Grisham, John',\n",
       " 'Atkins, Robert C.',\n",
       " 'Pullman, Philip',\n",
       " 'Truss, Lynne',\n",
       " 'Smith, Delia',\n",
       " 'Harris, Joanne',\n",
       " 'Boyne, John',\n",
       " 'Picoult, Jodi',\n",
       " 'Pullman, Philip',\n",
       " 'Lee, Harper',\n",
       " 'Gray, John',\n",
       " 'French, Dawn',\n",
       " 'Lewycka, Marina',\n",
       " 'Harris, Thomas',\n",
       " 'Tolkien, J. R. R.',\n",
       " 'Moore, Michael',\n",
       " 'Rubenfeld, Jed',\n",
       " 'Osbourne, Sharon',\n",
       " 'Coelho, Paulo',\n",
       " \"O'Grady, Paul\",\n",
       " 'Bryson, Bill',\n",
       " 'Oliver, Jamie',\n",
       " 'Fielding, Helen',\n",
       " 'Oliver, Jamie',\n",
       " 'McKenna, Paul',\n",
       " 'Bryson, Bill',\n",
       " 'Grisham, John',\n",
       " 'Levy, Andrea',\n",
       " 'Lawson, Nigella',\n",
       " 'Ali, Monica',\n",
       " 'Edwards, Kim',\n",
       " 'Donaldson, Julia',\n",
       " 'Hornby, Nick',\n",
       " 'Brand, Russell',\n",
       " 'Dawkins, Richard',\n",
       " '0',\n",
       " 'Smith, Zadie',\n",
       " 'Morton, Kate',\n",
       " 'Zusak, Markus',\n",
       " 'Binchy, Maeve',\n",
       " 'Harris, Robert',\n",
       " 'Oliver, Jamie',\n",
       " 'Collins, Suzanne',\n",
       " 'Pelzer, Dave',\n",
       " 'Oliver, Jamie']"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Author_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "1be8e191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(Author_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "3e409495",
   "metadata": {},
   "outputs": [],
   "source": [
    "Volumes_sold = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "79478653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping Volumes_sold from the given page\n",
    "Volumes_sold_tags=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"][1]/tbody/tr/td[4]')\n",
    "for i in Volumes_sold_tags:\n",
    "    Volumes=i.text\n",
    "    Volumes_sold.append(Volumes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "f8837ab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5,094,805',\n",
       " '4,475,152',\n",
       " '4,200,654',\n",
       " '4,179,479',\n",
       " '3,758,936',\n",
       " '3,583,215',\n",
       " '3,484,047',\n",
       " '3,377,906',\n",
       " '3,193,946',\n",
       " '2,950,264',\n",
       " '2,479,784',\n",
       " '2,315,405',\n",
       " '2,233,570',\n",
       " '2,193,928',\n",
       " '2,183,031',\n",
       " '2,152,737',\n",
       " '2,062,145',\n",
       " '2,052,876',\n",
       " '2,005,598',\n",
       " '1,979,552',\n",
       " '1,928,900',\n",
       " '1,852,919',\n",
       " '1,814,784',\n",
       " '1,787,118',\n",
       " '1,783,535',\n",
       " '1,781,269',\n",
       " '1,743,266',\n",
       " '1,629,119',\n",
       " '1,616,068',\n",
       " '1,583,992',\n",
       " '1,555,135',\n",
       " '1,546,886',\n",
       " '1,539,428',\n",
       " '1,508,205',\n",
       " '1,489,403',\n",
       " '1,352,318',\n",
       " '1,310,207',\n",
       " '1,310,176',\n",
       " '1,231,957',\n",
       " '1,217,712',\n",
       " '1,208,711',\n",
       " '1,204,058',\n",
       " '1,184,967',\n",
       " '1,181,503',\n",
       " '1,181,093',\n",
       " '1,153,181',\n",
       " '1,132,336',\n",
       " '1,130,802',\n",
       " '1,126,337',\n",
       " '1,115,549',\n",
       " '1,108,328',\n",
       " '1,107,379',\n",
       " '1,104,403',\n",
       " '1,092,349',\n",
       " '1,090,847',\n",
       " '1,087,262',\n",
       " '1,054,196',\n",
       " '1,037,160',\n",
       " '1,023,688',\n",
       " '1,015,956',\n",
       " '1,009,873',\n",
       " '1,004,414',\n",
       " '1,003,780',\n",
       " '1,002,314',\n",
       " '998,213',\n",
       " '992,846',\n",
       " '986,753',\n",
       " '986,115',\n",
       " '970,509',\n",
       " '967,466',\n",
       " '963,353',\n",
       " '962,515',\n",
       " '959,496',\n",
       " '956,114',\n",
       " '945,640',\n",
       " '931,312',\n",
       " '925,425',\n",
       " '924,695',\n",
       " '906,968',\n",
       " '905,086',\n",
       " '890,847',\n",
       " '869,671',\n",
       " '869,659',\n",
       " '862,602',\n",
       " '856,540',\n",
       " '845,858',\n",
       " '842,535',\n",
       " '828,215',\n",
       " '820,563',\n",
       " '816,907',\n",
       " '816,585',\n",
       " '815,586',\n",
       " '814,370',\n",
       " '809,641',\n",
       " '808,900',\n",
       " '807,311',\n",
       " '794,201',\n",
       " '792,187',\n",
       " '791,507',\n",
       " '791,095']"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Volumes_sold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "b3438bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(Volumes_sold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "82ff1d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "Publisher = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "16201e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping Volumes_sold from the given page\n",
    "publisher_tags=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"][1]/tbody/tr/td[5]')\n",
    "for i in publisher_tags:\n",
    "    publisher=i.text\n",
    "    Publisher.append(publisher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "2345e802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Transworld',\n",
       " 'Bloomsbury',\n",
       " 'Bloomsbury',\n",
       " 'Bloomsbury',\n",
       " 'Random House',\n",
       " 'Bloomsbury',\n",
       " 'Bloomsbury',\n",
       " 'Bloomsbury',\n",
       " 'Transworld',\n",
       " 'Bloomsbury',\n",
       " 'Random House',\n",
       " 'Little, Brown Book',\n",
       " 'Quercus',\n",
       " 'Random House',\n",
       " 'Transworld',\n",
       " 'Little, Brown Book',\n",
       " 'Transworld',\n",
       " 'Little, Brown Book',\n",
       " 'Pan Macmillan',\n",
       " 'Random House',\n",
       " 'Transworld',\n",
       " 'Transworld',\n",
       " 'Quercus',\n",
       " 'Little, Brown Book',\n",
       " 'Penguin',\n",
       " 'Pan Macmillan',\n",
       " 'Penguin',\n",
       " 'Bloomsbury',\n",
       " 'Hodder & Stoughton',\n",
       " 'Bloomsbury',\n",
       " 'Quercus',\n",
       " 'Random House',\n",
       " 'Random House',\n",
       " 'Pan Macmillan',\n",
       " 'Penguin',\n",
       " 'Random House',\n",
       " 'Random House',\n",
       " 'Canongate',\n",
       " 'HarperCollins',\n",
       " 'Orion',\n",
       " 'Pan Macmillan',\n",
       " 'HarperCollins',\n",
       " 'Random House',\n",
       " 'Scholastic Ltd.',\n",
       " 'Orion',\n",
       " 'Bloomsbury',\n",
       " 'Penguin',\n",
       " 'HarperCollins',\n",
       " 'Random House',\n",
       " 'Little, Brown Book',\n",
       " 'Headline',\n",
       " 'HarperCollins',\n",
       " 'Penguin',\n",
       " 'Orion',\n",
       " 'Bloomsbury',\n",
       " 'Random House',\n",
       " 'Random House',\n",
       " 'Scholastic Ltd.',\n",
       " 'Profile Books Group',\n",
       " 'Random House',\n",
       " 'Transworld',\n",
       " 'Random House Childrens Books G',\n",
       " 'Hodder & Stoughton',\n",
       " 'Scholastic Ltd.',\n",
       " 'Random House',\n",
       " 'HarperCollins',\n",
       " 'Random House',\n",
       " 'Penguin',\n",
       " 'Random House',\n",
       " 'HarperCollins',\n",
       " 'Penguin',\n",
       " 'Headline',\n",
       " 'Little, Brown Book',\n",
       " 'HarperCollins',\n",
       " 'Transworld',\n",
       " 'Transworld',\n",
       " 'Penguin',\n",
       " 'Pan Macmillan',\n",
       " 'Penguin',\n",
       " 'Transworld',\n",
       " 'Transworld',\n",
       " 'Random House',\n",
       " 'Headline',\n",
       " 'Random House',\n",
       " 'Transworld',\n",
       " 'Penguin',\n",
       " 'Pan Macmillan',\n",
       " 'Penguin',\n",
       " 'Hodder & Stoughton',\n",
       " 'Transworld',\n",
       " 'D.C. Thomson',\n",
       " 'Penguin',\n",
       " 'Pan Macmillan',\n",
       " 'Transworld',\n",
       " 'Orion',\n",
       " 'Random House',\n",
       " 'Penguin',\n",
       " 'Scholastic Ltd.',\n",
       " 'Orion',\n",
       " 'Penguin']"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Publisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "455267ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(Publisher))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "5139a597",
   "metadata": {},
   "outputs": [],
   "source": [
    "Genre = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "21b177b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping Genre from the given page\n",
    "Genre_tags=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"][1]/tbody/tr/td[6]')\n",
    "for i in Genre_tags:\n",
    "    genre=i.text\n",
    "    Genre.append(genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "66052895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Crime, Thriller & Adventure',\n",
       " \"Children's Fiction\",\n",
       " \"Children's Fiction\",\n",
       " \"Children's Fiction\",\n",
       " 'Romance & Sagas',\n",
       " \"Children's Fiction\",\n",
       " \"Children's Fiction\",\n",
       " \"Children's Fiction\",\n",
       " 'Crime, Thriller & Adventure',\n",
       " \"Children's Fiction\",\n",
       " 'Romance & Sagas',\n",
       " 'Young Adult Fiction',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Romance & Sagas',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Young Adult Fiction',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Young Adult Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Popular Science',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Young Adult Fiction',\n",
       " 'Picture Books',\n",
       " 'Picture Books',\n",
       " 'Food & Drink: General',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Humour: Collections & General',\n",
       " 'General & Literary Fiction',\n",
       " 'Autobiography: General',\n",
       " 'General & Literary Fiction',\n",
       " 'Biography: The Arts',\n",
       " 'Autobiography: General',\n",
       " 'Picture Books',\n",
       " 'Autobiography: General',\n",
       " 'General & Literary Fiction',\n",
       " 'Young Adult Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Science Fiction & Fantasy',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Fitness & Diet',\n",
       " 'General & Literary Fiction',\n",
       " \"Children's Fiction\",\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Fitness & Diet',\n",
       " 'Young Adult Fiction',\n",
       " 'Usage & Writing Guides',\n",
       " 'Food & Drink: General',\n",
       " 'General & Literary Fiction',\n",
       " 'Young Adult Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Young Adult Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Popular Culture & Media: General Interest',\n",
       " 'Autobiography: The Arts',\n",
       " 'General & Literary Fiction',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Science Fiction & Fantasy',\n",
       " 'Current Affairs & Issues',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Autobiography: The Arts',\n",
       " 'General & Literary Fiction',\n",
       " 'Autobiography: The Arts',\n",
       " 'Travel Writing',\n",
       " 'Food & Drink: General',\n",
       " 'General & Literary Fiction',\n",
       " 'National & Regional Cuisine',\n",
       " 'Fitness & Diet',\n",
       " 'Travel Writing',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'General & Literary Fiction',\n",
       " 'Food & Drink: General',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Picture Books',\n",
       " 'General & Literary Fiction',\n",
       " 'Autobiography: The Arts',\n",
       " 'Popular Science',\n",
       " \"Children's Annuals\",\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Food & Drink: General',\n",
       " 'Young Adult Fiction',\n",
       " 'Biography: General',\n",
       " 'Food & Drink: General']"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "96643f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(Genre))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106920b2",
   "metadata": {},
   "source": [
    "# Q9 Scrape the details most watched tv series of all time from imdb.com.\n",
    "Url = https://www.imdb.com/list/ls095964455/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "96db5ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.imdb.com/list/ls095964455/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "ffa6c860",
   "metadata": {},
   "outputs": [],
   "source": [
    "Name = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "f59030a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping Name from the given page\n",
    "Name_tags=driver.find_elements(By.XPATH,'//h3[@class=\"lister-item-header\"]')\n",
    "for i in Name_tags:\n",
    "    name=i.text\n",
    "    Name.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "63dfa3fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1. Game of Thrones (2011–2019)',\n",
       " '2. Stranger Things (2016– )',\n",
       " '3. The Walking Dead (2010–2022)',\n",
       " '4. 13 Reasons Why (2017–2020)',\n",
       " '5. The 100 (2014–2020)',\n",
       " '6. Orange Is the New Black (2013–2019)',\n",
       " '7. Riverdale (2017– )',\n",
       " \"8. Grey's Anatomy (2005– )\",\n",
       " '9. The Flash (2014–2023)',\n",
       " '10. Arrow (2012–2020)',\n",
       " '11. Money Heist (2017–2021)',\n",
       " '12. The Big Bang Theory (2007–2019)',\n",
       " '13. Black Mirror (2011–2019)',\n",
       " '14. Sherlock (2010–2017)',\n",
       " '15. Vikings (2013–2020)',\n",
       " '16. Pretty Little Liars (2010–2017)',\n",
       " '17. The Vampire Diaries (2009–2017)',\n",
       " '18. American Horror Story (2011– )',\n",
       " '19. Breaking Bad (2008–2013)',\n",
       " '20. Lucifer (2016–2021)',\n",
       " '21. Supernatural (2005–2020)',\n",
       " '22. Prison Break (2005–2017)',\n",
       " '23. How to Get Away with Murder (2014–2020)',\n",
       " '24. Teen Wolf (2011–2017)',\n",
       " '25. The Simpsons (1989– )',\n",
       " '26. Once Upon a Time (2011–2018)',\n",
       " '27. Narcos (2015–2017)',\n",
       " '28. Daredevil (2015–2018)',\n",
       " '29. Friends (1994–2004)',\n",
       " '30. How I Met Your Mother (2005–2014)',\n",
       " '31. Suits (2011–2019)',\n",
       " '32. Mr. Robot (2015–2019)',\n",
       " '33. The Originals (2013–2018)',\n",
       " '34. Supergirl (2015–2021)',\n",
       " '35. Gossip Girl (2007–2012)',\n",
       " '36. Sense8 (2015–2018)',\n",
       " '37. Gotham (2014–2019)',\n",
       " '38. Westworld (2016– )',\n",
       " '39. Jessica Jones (2015–2019)',\n",
       " '40. Modern Family (2009–2020)',\n",
       " '41. Rick and Morty (2013– )',\n",
       " '42. Shadowhunters (2016–2019)',\n",
       " '43. The End of the F***ing World (2017–2019)',\n",
       " '44. House of Cards (2013–2018)',\n",
       " '45. Dark (2017–2020)',\n",
       " '46. Elite (2018– )',\n",
       " '47. Sex Education (2019– )',\n",
       " '48. Shameless (2011–2021)',\n",
       " '49. New Girl (2011–2018)',\n",
       " '50. Agents of S.H.I.E.L.D. (2013–2020)',\n",
       " '51. You (2018– )',\n",
       " '52. Dexter (2006–2013)',\n",
       " '53. Fear the Walking Dead (2015– )',\n",
       " '54. Family Guy (1999– )',\n",
       " '55. The Blacklist (2013– )',\n",
       " '56. Lost (2004–2010)',\n",
       " '57. Peaky Blinders (2013–2022)',\n",
       " '58. House (2004–2012)',\n",
       " '59. Quantico (2015–2018)',\n",
       " '60. Orphan Black (2013–2017)',\n",
       " '61. Homeland (2011–2020)',\n",
       " '62. Blindspot (2015–2020)',\n",
       " \"63. DC's Legends of Tomorrow (2016–2022)\",\n",
       " \"64. The Handmaid's Tale (2017– )\",\n",
       " '65. Chilling Adventures of Sabrina (2018–2020)',\n",
       " '66. The Good Doctor (2017– )',\n",
       " '67. Jane the Virgin (2014–2019)',\n",
       " '68. Glee (2009–2015)',\n",
       " '69. South Park (1997– )',\n",
       " '70. Brooklyn Nine-Nine (2013–2021)',\n",
       " '71. Under the Dome (2013–2015)',\n",
       " '72. The Umbrella Academy (2019–2023)',\n",
       " '73. True Detective (2014–2019)',\n",
       " '74. The OA (2016–2019)',\n",
       " '75. Desperate Housewives (2004–2012)',\n",
       " '76. Better Call Saul (2015–2022)',\n",
       " '77. Bates Motel (2013–2017)',\n",
       " '78. The Punisher (2017–2019)',\n",
       " '79. Atypical (2017– )',\n",
       " '80. Dynasty (2017–2022)',\n",
       " '81. This Is Us (2016–2022)',\n",
       " '82. The Good Place (2016–2020)',\n",
       " '83. Iron Fist (2017–2018)',\n",
       " '84. The Rain (2018–2020)',\n",
       " '85. Mindhunter (2017–2019)',\n",
       " '86. Revenge (2011–2015)',\n",
       " '87. Luke Cage (2016–2018)',\n",
       " '88. Scandal (2012–2018)',\n",
       " '89. The Defenders (2017)',\n",
       " '90. Big Little Lies (2017–2019)',\n",
       " '91. Insatiable (2018–2019)',\n",
       " '92. The Mentalist (2008–2015)',\n",
       " '93. The Crown (2016– )',\n",
       " '94. Chernobyl (2019)',\n",
       " '95. iZombie (2015–2019)',\n",
       " '96. Reign (2013–2017)',\n",
       " '97. A Series of Unfortunate Events (2017–2019)',\n",
       " '98. Criminal Minds (2005–2020)',\n",
       " '99. Scream: The TV Series (2015–2019)',\n",
       " '100. The Haunting of Hill House (2018)']"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "20cae7bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(Name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "ecf40890",
   "metadata": {},
   "outputs": [],
   "source": [
    "Year_span = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "45ff4ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping Year span from the given page\n",
    "Year_span_tags=driver.find_elements(By.XPATH,'//span[@class=\"lister-item-year text-muted unbold\"]')\n",
    "for i in Year_span_tags:\n",
    "    year_span=i.text\n",
    "    Year_span.append(year_span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "771d1c4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(2011–2019)',\n",
       " '(2016– )',\n",
       " '(2010–2022)',\n",
       " '(2017–2020)',\n",
       " '(2014–2020)',\n",
       " '(2013–2019)',\n",
       " '(2017– )',\n",
       " '(2005– )',\n",
       " '(2014–2023)',\n",
       " '(2012–2020)',\n",
       " '(2017–2021)',\n",
       " '(2007–2019)',\n",
       " '(2011–2019)',\n",
       " '(2010–2017)',\n",
       " '(2013–2020)',\n",
       " '(2010–2017)',\n",
       " '(2009–2017)',\n",
       " '(2011– )',\n",
       " '(2008–2013)',\n",
       " '(2016–2021)',\n",
       " '(2005–2020)',\n",
       " '(2005–2017)',\n",
       " '(2014–2020)',\n",
       " '(2011–2017)',\n",
       " '(1989– )',\n",
       " '(2011–2018)',\n",
       " '(2015–2017)',\n",
       " '(2015–2018)',\n",
       " '(1994–2004)',\n",
       " '(2005–2014)',\n",
       " '(2011–2019)',\n",
       " '(2015–2019)',\n",
       " '(2013–2018)',\n",
       " '(2015–2021)',\n",
       " '(2007–2012)',\n",
       " '(2015–2018)',\n",
       " '(2014–2019)',\n",
       " '(2016– )',\n",
       " '(2015–2019)',\n",
       " '(2009–2020)',\n",
       " '(2013– )',\n",
       " '(2016–2019)',\n",
       " '(2017–2019)',\n",
       " '(2013–2018)',\n",
       " '(2017–2020)',\n",
       " '(2018– )',\n",
       " '(2019– )',\n",
       " '(2011–2021)',\n",
       " '(2011–2018)',\n",
       " '(2013–2020)',\n",
       " '(2018– )',\n",
       " '(2006–2013)',\n",
       " '(2015– )',\n",
       " '(1999– )',\n",
       " '(2013– )',\n",
       " '(2004–2010)',\n",
       " '(2013–2022)',\n",
       " '(2004–2012)',\n",
       " '(2015–2018)',\n",
       " '(2013–2017)',\n",
       " '(2011–2020)',\n",
       " '(2015–2020)',\n",
       " '(2016–2022)',\n",
       " '(2017– )',\n",
       " '(2018–2020)',\n",
       " '(2017– )',\n",
       " '(2014–2019)',\n",
       " '(2009–2015)',\n",
       " '(1997– )',\n",
       " '(2013–2021)',\n",
       " '(2013–2015)',\n",
       " '(2019–2023)',\n",
       " '(2014–2019)',\n",
       " '(2016–2019)',\n",
       " '(2004–2012)',\n",
       " '(2015–2022)',\n",
       " '(2013–2017)',\n",
       " '(2017–2019)',\n",
       " '(2017– )',\n",
       " '(2017–2022)',\n",
       " '(2016–2022)',\n",
       " '(2016–2020)',\n",
       " '(2017–2018)',\n",
       " '(2018–2020)',\n",
       " '(2017–2019)',\n",
       " '(2011–2015)',\n",
       " '(2016–2018)',\n",
       " '(2012–2018)',\n",
       " '(2017)',\n",
       " '(2017–2019)',\n",
       " '(2018–2019)',\n",
       " '(2008–2015)',\n",
       " '(2016– )',\n",
       " '(2019)',\n",
       " '(2015–2019)',\n",
       " '(2013–2017)',\n",
       " '(2017–2019)',\n",
       " '(2005–2020)',\n",
       " '(2015–2019)',\n",
       " '(2018)']"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Year_span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "559ead48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(Year_span))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "fb4bada8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Genre = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "d89e96ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping Genre from the given page\n",
    "Genre_tags=driver.find_elements(By.XPATH,'//span[@class=\"genre\"]')\n",
    "for i in Genre_tags:\n",
    "    genre=i.text\n",
    "    Genre.append(genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "f08dcba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Action, Adventure, Drama',\n",
       " 'Drama, Fantasy, Horror',\n",
       " 'Drama, Horror, Thriller',\n",
       " 'Drama, Mystery, Thriller',\n",
       " 'Drama, Mystery, Sci-Fi',\n",
       " 'Comedy, Crime, Drama',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Drama, Romance',\n",
       " 'Action, Adventure, Drama',\n",
       " 'Action, Adventure, Crime',\n",
       " 'Action, Crime, Drama',\n",
       " 'Comedy, Romance',\n",
       " 'Drama, Mystery, Sci-Fi',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Action, Adventure, Drama',\n",
       " 'Drama, Mystery, Romance',\n",
       " 'Drama, Fantasy, Horror',\n",
       " 'Drama, Horror, Sci-Fi',\n",
       " 'Crime, Drama, Thriller',\n",
       " 'Crime, Drama, Fantasy',\n",
       " 'Drama, Fantasy, Horror',\n",
       " 'Action, Crime, Drama',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Action, Drama, Fantasy',\n",
       " 'Animation, Comedy',\n",
       " 'Adventure, Fantasy, Romance',\n",
       " 'Biography, Crime, Drama',\n",
       " 'Action, Crime, Drama',\n",
       " 'Comedy, Romance',\n",
       " 'Comedy, Romance',\n",
       " 'Comedy, Drama',\n",
       " 'Crime, Drama, Thriller',\n",
       " 'Drama, Fantasy, Horror',\n",
       " 'Action, Adventure, Drama',\n",
       " 'Drama, Romance',\n",
       " 'Drama, Mystery, Sci-Fi',\n",
       " 'Action, Crime, Drama',\n",
       " 'Drama, Mystery, Sci-Fi',\n",
       " 'Action, Crime, Drama',\n",
       " 'Comedy, Drama, Romance',\n",
       " 'Animation, Adventure, Comedy',\n",
       " 'Action, Drama, Fantasy',\n",
       " 'Adventure, Comedy, Crime',\n",
       " 'Drama',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Crime, Drama, Thriller',\n",
       " 'Comedy, Drama',\n",
       " 'Comedy, Drama',\n",
       " 'Comedy, Romance',\n",
       " 'Action, Adventure, Drama',\n",
       " 'Crime, Drama, Romance',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Drama, Horror, Sci-Fi',\n",
       " 'Animation, Comedy',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Adventure, Drama, Fantasy',\n",
       " 'Crime, Drama',\n",
       " 'Drama, Mystery',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Drama, Sci-Fi, Thriller',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Action, Crime, Drama',\n",
       " 'Action, Adventure, Drama',\n",
       " 'Drama, Sci-Fi, Thriller',\n",
       " 'Drama, Fantasy, Horror',\n",
       " 'Drama',\n",
       " 'Comedy',\n",
       " 'Comedy, Drama, Music',\n",
       " 'Animation, Comedy',\n",
       " 'Comedy, Crime',\n",
       " 'Drama, Mystery, Sci-Fi',\n",
       " 'Action, Adventure, Comedy',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Drama, Fantasy, Mystery',\n",
       " 'Comedy, Drama, Mystery',\n",
       " 'Crime, Drama',\n",
       " 'Drama, Horror, Mystery',\n",
       " 'Action, Crime, Drama',\n",
       " 'Comedy, Drama',\n",
       " 'Drama',\n",
       " 'Comedy, Drama, Romance',\n",
       " 'Comedy, Drama, Fantasy',\n",
       " 'Action, Adventure, Crime',\n",
       " 'Drama, Sci-Fi, Thriller',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Drama, Mystery, Thriller',\n",
       " 'Action, Crime, Drama',\n",
       " 'Drama, Thriller',\n",
       " 'Action, Adventure, Crime',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Comedy, Drama, Thriller',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Biography, Drama, History',\n",
       " 'Drama, History, Thriller',\n",
       " 'Comedy, Crime, Drama',\n",
       " 'Drama',\n",
       " 'Adventure, Comedy, Drama',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Comedy, Crime, Drama',\n",
       " 'Drama, Horror, Mystery']"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "44f14f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(Genre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "49387f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "Run_time = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "d776d1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping Run_time from the given page\n",
    "Run_time_tags=driver.find_elements(By.XPATH,'//span[@class=\"runtime\"]')\n",
    "for i in Run_time_tags:\n",
    "    run_time=i.text\n",
    "    Run_time.append(run_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "96b4c098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['57 min',\n",
       " '51 min',\n",
       " '44 min',\n",
       " '60 min',\n",
       " '43 min',\n",
       " '59 min',\n",
       " '45 min',\n",
       " '41 min',\n",
       " '43 min',\n",
       " '42 min',\n",
       " '70 min',\n",
       " '22 min',\n",
       " '60 min',\n",
       " '88 min',\n",
       " '44 min',\n",
       " '44 min',\n",
       " '43 min',\n",
       " '60 min',\n",
       " '49 min',\n",
       " '42 min',\n",
       " '44 min',\n",
       " '44 min',\n",
       " '43 min',\n",
       " '41 min',\n",
       " '22 min',\n",
       " '60 min',\n",
       " '49 min',\n",
       " '54 min',\n",
       " '22 min',\n",
       " '22 min',\n",
       " '44 min',\n",
       " '49 min',\n",
       " '45 min',\n",
       " '43 min',\n",
       " '42 min',\n",
       " '60 min',\n",
       " '42 min',\n",
       " '62 min',\n",
       " '56 min',\n",
       " '22 min',\n",
       " '23 min',\n",
       " '42 min',\n",
       " '25 min',\n",
       " '51 min',\n",
       " '60 min',\n",
       " '60 min',\n",
       " '45 min',\n",
       " '46 min',\n",
       " '22 min',\n",
       " '45 min',\n",
       " '45 min',\n",
       " '53 min',\n",
       " '44 min',\n",
       " '22 min',\n",
       " '43 min',\n",
       " '44 min',\n",
       " '60 min',\n",
       " '44 min',\n",
       " '42 min',\n",
       " '44 min',\n",
       " '55 min',\n",
       " '42 min',\n",
       " '42 min',\n",
       " '60 min',\n",
       " '60 min',\n",
       " '41 min',\n",
       " '60 min',\n",
       " '44 min',\n",
       " '22 min',\n",
       " '22 min',\n",
       " '43 min',\n",
       " '60 min',\n",
       " '55 min',\n",
       " '60 min',\n",
       " '45 min',\n",
       " '46 min',\n",
       " '45 min',\n",
       " '53 min',\n",
       " '30 min',\n",
       " '42 min',\n",
       " '45 min',\n",
       " '22 min',\n",
       " '55 min',\n",
       " '45 min',\n",
       " '60 min',\n",
       " '44 min',\n",
       " '55 min',\n",
       " '43 min',\n",
       " '50 min',\n",
       " '60 min',\n",
       " '45 min',\n",
       " '43 min',\n",
       " '58 min',\n",
       " '330 min',\n",
       " '42 min',\n",
       " '42 min',\n",
       " '50 min',\n",
       " '42 min',\n",
       " '45 min',\n",
       " '572 min']"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Run_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "4a412233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(Run_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "9d45bb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ratings = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "706eaa19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping Ratings from the given page\n",
    "ratings_tags=driver.find_elements(By.XPATH,'//div[@class=\"ipl-rating-widget\"]')\n",
    "for i in ratings_tags:\n",
    "    ratings=i.text\n",
    "    Ratings.append(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "96f0ebce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['9.2\\nRate',\n",
       " '8.7\\nRate',\n",
       " '8.1\\nRate',\n",
       " '7.5\\nRate',\n",
       " '7.6\\nRate',\n",
       " '8.1\\nRate',\n",
       " '6.6\\nRate',\n",
       " '7.6\\nRate',\n",
       " '7.6\\nRate',\n",
       " '7.5\\nRate',\n",
       " '8.2\\nRate',\n",
       " '8.2\\nRate',\n",
       " '8.8\\nRate',\n",
       " '9.1\\nRate',\n",
       " '8.5\\nRate',\n",
       " '7.4\\nRate',\n",
       " '7.7\\nRate',\n",
       " '8\\nRate',\n",
       " '9.5\\nRate',\n",
       " '8.1\\nRate',\n",
       " '8.4\\nRate',\n",
       " '8.3\\nRate',\n",
       " '8.1\\nRate',\n",
       " '7.7\\nRate',\n",
       " '8.7\\nRate',\n",
       " '7.7\\nRate',\n",
       " '8.8\\nRate',\n",
       " '8.6\\nRate',\n",
       " '8.9\\nRate',\n",
       " '8.3\\nRate',\n",
       " '8.5\\nRate',\n",
       " '8.6\\nRate',\n",
       " '8.3\\nRate',\n",
       " '6.2\\nRate',\n",
       " '7.5\\nRate',\n",
       " '8.2\\nRate',\n",
       " '7.8\\nRate',\n",
       " '8.5\\nRate',\n",
       " '7.9\\nRate',\n",
       " '8.5\\nRate',\n",
       " '9.2\\nRate',\n",
       " '6.5\\nRate',\n",
       " '8.1\\nRate',\n",
       " '8.7\\nRate',\n",
       " '8.7\\nRate',\n",
       " '7.4\\nRate',\n",
       " '8.4\\nRate',\n",
       " '8.6\\nRate',\n",
       " '7.8\\nRate',\n",
       " '7.5\\nRate',\n",
       " '7.7\\nRate',\n",
       " '8.7\\nRate',\n",
       " '6.8\\nRate',\n",
       " '8.2\\nRate',\n",
       " '8\\nRate',\n",
       " '8.3\\nRate',\n",
       " '8.8\\nRate',\n",
       " '8.7\\nRate',\n",
       " '6.7\\nRate',\n",
       " '8.3\\nRate',\n",
       " '8.3\\nRate',\n",
       " '7.3\\nRate',\n",
       " '6.8\\nRate',\n",
       " '8.4\\nRate',\n",
       " '7.4\\nRate',\n",
       " '8.1\\nRate',\n",
       " '7.9\\nRate',\n",
       " '6.8\\nRate',\n",
       " '8.7\\nRate',\n",
       " '8.4\\nRate',\n",
       " '6.5\\nRate',\n",
       " '7.9\\nRate',\n",
       " '8.9\\nRate',\n",
       " '7.8\\nRate',\n",
       " '7.6\\nRate',\n",
       " '8.9\\nRate',\n",
       " '8.1\\nRate',\n",
       " '8.5\\nRate',\n",
       " '8.3\\nRate',\n",
       " '7.2\\nRate',\n",
       " '8.7\\nRate',\n",
       " '8.2\\nRate',\n",
       " '6.4\\nRate',\n",
       " '6.3\\nRate',\n",
       " '8.6\\nRate',\n",
       " '7.9\\nRate',\n",
       " '7.3\\nRate',\n",
       " '7.7\\nRate',\n",
       " '7.2\\nRate',\n",
       " '8.5\\nRate',\n",
       " '6.5\\nRate',\n",
       " '8.1\\nRate',\n",
       " '8.7\\nRate',\n",
       " '9.4\\nRate',\n",
       " '7.8\\nRate',\n",
       " '7.4\\nRate',\n",
       " '7.8\\nRate',\n",
       " '8.1\\nRate',\n",
       " '7.1\\nRate',\n",
       " '8.6\\nRate']"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "eb6924e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(Ratings))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7603880",
   "metadata": {},
   "source": [
    "# Q10. Details of Datasets from UCI machine learning repositories.\n",
    "Url = https://archive.ics.uci.edu/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "84e8869d",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://archive.ics.uci.edu/ml/datasets.php')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "d8175f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset_name = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40ab906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping Dataset_name from the given page\n",
    "Dataset_name_tags=driver.find_elements(By.XPATH,\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr[2]/td[1]/table/tbody/tr/td[2]/p/b\")\n",
    "for i in Dataset_name_tags:\n",
    "    dataset=i.text\n",
    "    Dataset_name.append(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "19574cf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Abalone']"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc50253b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
